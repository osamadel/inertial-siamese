{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Experiments"
   ],
   "metadata": {
    "id": "mvAor71-TFxU"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Roughly speaking, I will try to use the models trained on the datasets, then remove the FC layer and add other classifiers. Then I will report the result of the other classifiers on the final performance using either EER or accuracy."
   ],
   "metadata": {
    "id": "-DBFcSs6TFxe"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "data_path = '../data/mmuisd/normal/pocket'\n",
    "results_path = '../results/'\n",
    "\n",
    "# data_path = '/content/drive/MyDrive/IJCNN/data/osaka'\n",
    "# results_path = '/content/drive/MyDrive/IJCNN/results'"
   ],
   "outputs": [],
   "metadata": {
    "id": "cOPS399rTFxe"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OI-lQFRRKEAY",
    "outputId": "7e85a733-61b5-4742-a5c2-2ed5b6502d45"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "!cp -r \"/content/drive/MyDrive/IJCNN/src\" /content/\n",
    "!mv src/datasets.py datasets.py\n",
    "!mv src/models.py models.py\n",
    "!mv src/analyze.py analyze.py\n",
    "!ls"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "analyze.py  datasets.py  drive\tmodels.py  sample_data\tsrc\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jArT8WzDKPH2",
    "outputId": "e463a28e-25ed-4c96-870b-9cfec0a36b87"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import datasets, models, analyze\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import activations\n",
    "# from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "# import nevergrad as ng\n",
    "import os\n",
    "np.set_printoptions(precision=4)\n",
    "gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ],
   "outputs": [],
   "metadata": {
    "id": "k0TFGFVAKTNo"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ],
   "outputs": [],
   "metadata": {
    "id": "Qwqf4RGPJ08n"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def prepare_data(train_sps, val_sps, test_sps, max_cls, split, data, labels, indices_list, run_n):\n",
    "    train_split = int(split[0] * max_cls)\n",
    "    val_split = int(split[2] * max_cls)\n",
    "\n",
    "    rand_indices = np.random.choice(range(max_cls), size=max_cls, replace=False)\n",
    "    indices_list.append(rand_indices)\n",
    "    print('Run #%d:'%run_n)\n",
    "    \n",
    "    all_data_rand, all_labels_rand = [data[x] for x in rand_indices], [labels[x] for x in rand_indices]\n",
    "    b_data, b_labels = datasets.generate_batch(train_sps, all_data_rand[:train_split], all_labels_rand[:train_split])\n",
    "    \n",
    "    val_data, val_labels = datasets.generate_batch(val_sps, all_data_rand[train_split:train_split+val_split], all_labels_rand[train_split:train_split+val_split])\n",
    "    ridx = np.random.choice(range(b_data[0].shape[0]), size=b_data[0].shape[0], replace=False)\n",
    "    \n",
    "    b_data_test, b_labels_test = datasets.generate_batch(test_sps, all_data_rand[train_split+val_split:], all_labels_rand[train_split+val_split:])\n",
    "\n",
    "    l_input = b_data[0][ridx]\n",
    "    r_input = b_data[1][ridx]\n",
    "    b_labels = b_labels[ridx]\n",
    "\n",
    "    # print(l_input[0].shape)\n",
    "\n",
    "    l_input_val = val_data[0]\n",
    "    r_input_val = val_data[1]\n",
    "\n",
    "    l_input_test = b_data_test[0]\n",
    "    r_input_test = b_data_test[1]\n",
    "    return l_input, r_input, b_labels, l_input_val, r_input_val, val_labels, l_input_test, r_input_test, b_labels_test"
   ],
   "outputs": [],
   "metadata": {
    "id": "jvrnb1vgKVPf"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def load_dataset(segLen, overlap, acc_only):\n",
    "    data, labels = datasets.load_segment_mmuisd(data_path, [0,120], segment_time=2)\n",
    "    return data, labels\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "JYx3YqoxK4PG"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def build_model1(input_shape, bn, reg):\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Conv1D, \\\n",
    "                                        MaxPooling1D, \\\n",
    "                                        AveragePooling1D, \\\n",
    "                                        Dense, Flatten, Dropout, \\\n",
    "                                        BatchNormalization, \\\n",
    "                                        GlobalMaxPooling1D, \\\n",
    "                                        GlobalAveragePooling1D, \\\n",
    "                                        Activation\n",
    "    from tensorflow.keras import activations\n",
    "    import tensorflow.keras.regularizers as regularizers\n",
    "\n",
    "    model = Sequential()\n",
    "    if reg:\n",
    "        model.add(Conv1D(16, 3, strides=1, input_shape=input_shape, \n",
    "                        kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                        bias_regularizer=regularizers.l2(1e-4)))\n",
    "    else:\n",
    "        model.add(Conv1D(16, 3, strides=1, input_shape=input_shape))\n",
    "    if bn:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Activation(activations.relu))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    if reg:\n",
    "        model.add(Conv1D(64, 5, strides=2, \n",
    "                        kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                        bias_regularizer=regularizers.l2(1e-4)))\n",
    "    else:\n",
    "        model.add(Conv1D(64, 5, strides=2))\n",
    "    if bn:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Activation(activations.relu))\n",
    "    model.add(AveragePooling1D(pool_size=2))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {
    "id": "-h4dUZV8WXlb"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# def build_model2(input_shape, bn, reg):\n",
    "#     from tensorflow.keras.models import Sequential\n",
    "#     from tensorflow.keras.layers import Conv1D, \\\n",
    "#                                         MaxPooling1D, \\\n",
    "#                                         AveragePooling1D, \\\n",
    "#                                         Dense, Flatten, Dropout, \\\n",
    "#                                         BatchNormalization, \\\n",
    "#                                         GlobalMaxPooling1D, \\\n",
    "#                                         GlobalAveragePooling1D, \\\n",
    "#                                         Activation\n",
    "#     from tensorflow.keras import activations\n",
    "#     import tensorflow.keras.regularizers as regularizers\n",
    "\n",
    "#     model = Sequential()\n",
    "#     if reg:\n",
    "#         model.add(Conv1D(16, 3, strides=1, activation='tanh', input_shape=input_shape, kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),bias_regularizer=regularizers.l2(1e-4)))\n",
    "#         model.add(Conv1D(32, 3, strides=2, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),bias_regularizer=regularizers.l2(1e-4)))\n",
    "#     else:\n",
    "#         model.add(Conv1D(16, 3, strides=1, activation='tanh', input_shape=input_shape))\n",
    "#         model.add(Conv1D(32, 3, strides=2, activation='relu'))\n",
    "    \n",
    "#     if bn:\n",
    "#         model.add(BatchNormalization())\n",
    "\n",
    "#     model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "#     if reg:\n",
    "#         model.add(Conv1D(64, 5, strides=2, activation='tanh', kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),bias_regularizer=regularizers.l2(1e-4)))\n",
    "#         model.add(Conv1D(128, 5, strides=3, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),bias_regularizer=regularizers.l2(1e-4)))\n",
    "#     else:\n",
    "#         model.add(Conv1D(64, 5, strides=2, activation='tanh'))\n",
    "#         model.add(Conv1D(128, 5, strides=3, activation='relu'))\n",
    "    \n",
    "#     if bn:\n",
    "#         model.add(BatchNormalization())\n",
    "\n",
    "#     model.add(GlobalMaxPooling1D())\n",
    "#     return model"
   ],
   "outputs": [],
   "metadata": {
    "id": "Auc0ROjJXJ4a"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# def build_model3(input_shape, bn, reg):\n",
    "#     from tensorflow.keras.models import Sequential\n",
    "#     from tensorflow.keras.layers import Conv1D, \\\n",
    "#                                         MaxPooling1D, \\\n",
    "#                                         AveragePooling1D, \\\n",
    "#                                         Dense, Flatten, Dropout, \\\n",
    "#                                         BatchNormalization, \\\n",
    "#                                         GlobalMaxPooling1D, \\\n",
    "#                                         GlobalAveragePooling1D, \\\n",
    "#                                         Activation\n",
    "#     from tensorflow.keras import activations\n",
    "#     import tensorflow.keras.regularizers as regularizers\n",
    "\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv1D(64, 5, strides=3, padding='valid', activation='relu', input_shape=input_shape))\n",
    "#     if bn: model.add(BatchNormalization())\n",
    "#     model.add(Conv1D(128, 3, strides=2, padding='valid', activation='relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "#     model.add(Conv1D(128, 2, strides=1, padding='valid', activation='tanh'))\n",
    "#     model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "#     model.add(GlobalMaxPooling1D())\n",
    "#     return model"
   ],
   "outputs": [],
   "metadata": {
    "id": "1S9BaZbCZajy"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def build_model4(input_shape, bn, reg):\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Conv1D, \\\n",
    "                                        MaxPooling1D, \\\n",
    "                                        AveragePooling1D, \\\n",
    "                                        Dense, Flatten, Dropout, \\\n",
    "                                        BatchNormalization, \\\n",
    "                                        GlobalMaxPooling1D, \\\n",
    "                                        GlobalAveragePooling1D, \\\n",
    "                                        Activation\n",
    "    from tensorflow.keras import activations\n",
    "    import tensorflow.keras.regularizers as regularizers\n",
    "\n",
    "    model = Sequential()\n",
    "    if reg:\n",
    "        model.add(Conv1D(32, 3, strides=1, input_shape=input_shape, \n",
    "                        kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                        bias_regularizer=regularizers.l2(1e-4)))\n",
    "    else:\n",
    "        model.add(Conv1D(32, 3, strides=1, input_shape=input_shape))\n",
    "    if bn:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Activation(activations.relu))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    if reg:\n",
    "        model.add(Conv1D(128, 5, strides=2, \n",
    "                        kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                        bias_regularizer=regularizers.l2(1e-4)))\n",
    "    else:\n",
    "        model.add(Conv1D(128, 5, strides=2))\n",
    "    if bn:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Activation(activations.relu))\n",
    "    model.add(AveragePooling1D(pool_size=2))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {
    "id": "q7x9rfwDIqx-"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def build_model5(input_shape, bn, reg):\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Conv1D, \\\n",
    "                                        MaxPooling1D, \\\n",
    "                                        AveragePooling1D, \\\n",
    "                                        Dense, Flatten, Dropout, \\\n",
    "                                        BatchNormalization, \\\n",
    "                                        GlobalMaxPooling1D, \\\n",
    "                                        GlobalAveragePooling1D, \\\n",
    "                                        Activation\n",
    "    from tensorflow.keras import activations\n",
    "    import tensorflow.keras.regularizers as regularizers\n",
    "\n",
    "    model = Sequential()\n",
    "    if reg:\n",
    "        model.add(Conv1D(64, 3, strides=1, input_shape=input_shape, \n",
    "                        kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                        bias_regularizer=regularizers.l2(1e-4)))\n",
    "    else:\n",
    "        model.add(Conv1D(64, 3, strides=1, input_shape=input_shape))\n",
    "    if bn:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Activation(activations.relu))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    if reg:\n",
    "        model.add(Conv1D(256, 5, strides=2, \n",
    "                        kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                        bias_regularizer=regularizers.l2(1e-4)))\n",
    "    else:\n",
    "        model.add(Conv1D(256, 5, strides=2))\n",
    "    if bn:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Activation(activations.relu))\n",
    "    model.add(AveragePooling1D(pool_size=2))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {
    "id": "F28ig3xVIzuJ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "acc_only_list    = [False, True]\n",
    "segLen_list      = [1, 2]\n",
    "overlap_list     = [0, 0.25, 0.5, 0.75]\n",
    "# models_list      = [build_model1, build_model2, build_model3]\n",
    "models_list      = [build_model4, build_model5]\n",
    "bn_list          = [True, False]\n",
    "reg_list         = [True, False]\n",
    "\n",
    "# Configurations\n",
    "train_sps       = 500\n",
    "val_sps         = 200\n",
    "test_sps        = 200\n",
    "max_cls         = 120\n",
    "split           = [0.8, 0.1, 0.1]\n",
    "output_dropout  = 0.1\n",
    "runs            = 10\n",
    "np.set_printoptions(precision=4)"
   ],
   "outputs": [],
   "metadata": {
    "id": "DFUOb5_GUo-e"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def getSiameseAcc(siamese, test_set, EER_th):\n",
    "    # l_input_test, r_input_test = test_set[0]\n",
    "    b_labels_test = test_set[1]\n",
    "    # print('EER threshold:', EER_th)\n",
    "    # print(np.uint8(np.squeeze(siamese.predict(test_set[0])) >= EER_th))\n",
    "    # print(b_labels_test)\n",
    "    return np.mean(np.uint8(np.squeeze(siamese.predict(test_set[0])) >= EER_th) == b_labels_test)\n",
    "\n",
    "def trainSVM(siamese, training_set, test_set):\n",
    "    l_input, r_input = training_set[0]\n",
    "    b_labels = training_set[1]\n",
    "    l_input_test, r_input_test = test_set[0]\n",
    "    b_labels_test = test_set[1]\n",
    "\n",
    "    # classifier = SVC(kernel='poly', degree=10, C=100)\n",
    "    classifier = SVC(kernel='poly', degree=5, C=10)\n",
    "    feature_exctractor = Model(inputs=[siamese.get_layer('left_input').input,siamese.get_layer('right_input').input], outputs=siamese.get_layer('lambda').output)\n",
    "    d_vect = feature_exctractor.predict([l_input, r_input])\n",
    "    d_vect_test = feature_exctractor.predict([l_input_test, r_input_test])\n",
    "    \n",
    "    # print(d_vect.shape)\n",
    "\n",
    "    classifier.fit(d_vect, b_labels)\n",
    "    svc_score = classifier.score(d_vect_test, b_labels_test)\n",
    "    # print('SVC mean test accuracy:', svc_score*100)\n",
    "    return svc_score\n",
    "\n",
    "def trainKNN(siamese, training_set, test_set):\n",
    "    l_input, r_input = training_set[0]\n",
    "    b_labels = training_set[1]\n",
    "    l_input_test, r_input_test = test_set[0]\n",
    "    b_labels_test = test_set[1]\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    feature_exctractor = Model(inputs=[siamese.get_layer('left_input').input,siamese.get_layer('right_input').input], outputs=siamese.get_layer('lambda').output)\n",
    "    d_vect = feature_exctractor.predict([l_input, r_input])\n",
    "    d_vect_test = feature_exctractor.predict([l_input_test, r_input_test])\n",
    "\n",
    "    knn.fit(d_vect, b_labels)\n",
    "    test_predictions = knn.predict(d_vect_test)\n",
    "    knn_score = knn.score(d_vect_test, b_labels_test)\n",
    "    # print('KNN mean test accuracy:', knn_score*100)\n",
    "    return knn_score\n",
    "\n",
    "def trainANN(siamese, training_set, test_set):\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "    l_input, r_input = training_set[0]\n",
    "    b_labels = training_set[1]\n",
    "    l_input_test, r_input_test = test_set[0]\n",
    "    b_labels_test = test_set[1]\n",
    "\n",
    "    feature_exctractor = Model(inputs=[siamese.get_layer('left_input').input,siamese.get_layer('right_input').input], outputs=siamese.get_layer('lambda').output)\n",
    "    d_vect = feature_exctractor.predict([l_input, r_input])\n",
    "    d_vect_test = feature_exctractor.predict([l_input_test, r_input_test])\n",
    "\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(8, activation='relu', input_shape=(256,)))\n",
    "    classifier.add(Dropout(0.3))\n",
    "    classifier.add(Dense(8, activation='relu'))\n",
    "    classifier.add(Dropout(0.3))\n",
    "    classifier.add(Dense(1, activation='sigmoid'))\n",
    "    classifier.compile(loss='binary_crossentropy', metrics=['acc'], optimizer='adam')\n",
    "\n",
    "    classifier.fit(d_vect, b_labels, verbose=0, epochs=20, batch_size=128)\n",
    "    # test_predictions = np.uint8(np.squeeze(classifier.predict(d_vect_test) >= 0.5))\n",
    "    # print(test_predictions[:10])\n",
    "    ann_score = classifier.evaluate(d_vect_test, b_labels_test)[1]\n",
    "    # print('ANN mean test accuracy:', ann_score*100)\n",
    "    return ann_score"
   ],
   "outputs": [],
   "metadata": {
    "id": "CxkqRdMpDOip"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "def one_run(train_sps, val_sps, test_sps, max_cls, split, data, labels, lst, run_n):\n",
    "    accuracies = {}\n",
    "    l_input, r_input, b_labels \\\n",
    "        , l_input_val, r_input_val, val_labels \\\n",
    "            , l_input_test, r_input_test, b_labels_test = prepare_data( train_sps,\n",
    "                                                                        val_sps,\n",
    "                                                                        test_sps,\n",
    "                                                                        max_cls,\n",
    "                                                                        split,\n",
    "                                                                        data,\n",
    "                                                                        labels,\n",
    "                                                                        [],\n",
    "                                                                        run_n)\n",
    "    print('Loaded data')\n",
    "    adam = Adam(learning_rate=0.001)\n",
    "    earlystop = EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "    \n",
    "    cnn = build_model5(l_input[0].shape, bn=1, reg=0)\n",
    "    siamese = models.build_siamese(l_input[0].shape, cnn, output_dropout)\n",
    "    siamese.compile(loss='binary_crossentropy', optimizer=adam, metrics=[BinaryAccuracy(name='accuracy')])\n",
    "    print('Built model')\n",
    "    if run_n == 0: \n",
    "        cnn.summary()\n",
    "    print('Start training ...')\n",
    "    hist = siamese.fit([l_input, r_input], \n",
    "                        b_labels, \n",
    "                        shuffle=True,\n",
    "                        batch_size=64,\n",
    "                        epochs=100,\n",
    "                        callbacks=[earlystop],\n",
    "                        validation_data=([l_input_val, r_input_val], val_labels),\n",
    "                        verbose=2\n",
    "                        )\n",
    "    print('Finished training')\n",
    "    siamese.save_weights(os.path.join(results_path, 'mmuisd', 'model_r{}_weights.h5'.format(run_n)))\n",
    "    print('Saved model')\n",
    "    FRR, FAR, EER, EER_th = analyze.ROC(siamese, [l_input_test, r_input_test], b_labels_test)\n",
    "    print('Siamese EER:', EER)\n",
    "    accuracies['siamese'] = getSiameseAcc(siamese, ([l_input_test, r_input_test], b_labels_test), EER_th)\n",
    "    print('Siamese Accuracy:', accuracies['siamese'])\n",
    "    accuracies['svm'] = trainSVM(siamese, ([l_input, r_input], b_labels), ([l_input_test, r_input_test], b_labels_test))\n",
    "    print('SVM Accuracy:', accuracies['svm'])\n",
    "    accuracies['ann'] = trainANN(siamese, ([l_input, r_input], b_labels), ([l_input_test, r_input_test], b_labels_test))\n",
    "    print('ANN Accuracy:', accuracies['ann'])\n",
    "    accuracies['knn'] = trainKNN(siamese, ([l_input, r_input], b_labels), ([l_input_test, r_input_test], b_labels_test))\n",
    "    print('KNN Accuracy:', accuracies['knn'])\n",
    "\n",
    "\n",
    "    return siamese, [FRR, FAR, EER, EER_th], accuracies"
   ],
   "outputs": [],
   "metadata": {
    "id": "N-z-EqS3TFxl"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Experiment 1: Train Different Classifiers"
   ],
   "metadata": {
    "id": "B7TKW9MyTFxl"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "data, labels = load_dataset(2, 0.75, acc_only=False)\n",
    "num_cls = 4 # number of classifiers\n",
    "total_accs = np.zeros((runs, num_cls))\n",
    "\n",
    "# Results of this configuration/experiment\n",
    "# EERs = np.array([np.zeros(runs) for _ in range(3*2*2)])\n",
    "\n",
    "for run_n in range(runs):\n",
    "    siamese, ROC, accs = one_run(train_sps, val_sps, test_sps, max_cls, split, data, labels, [], run_n)\n",
    "    for ii, c in enumerate(accs):\n",
    "        total_accs[run_n, ii] = accs[c]\n",
    "    \n",
    "    np.save(os.path.join(results_path, 'mmuisd', 'classifiers.npy'), total_accs)\n",
    "    \n",
    "#     EERs[4 * model_index + 2*bn + reg , run_n] = EER\n",
    "#     np.save(results_path + 'osaka_filters_eers2.npy', EERs)\n",
    "\n",
    "for ii, c in enumerate(accs):\n",
    "    print(total_accs[:,ii])\n",
    "    print('{} accuracy: {} +/- {}'.format(c, total_accs[:,ii].mean(), total_accs[:,ii].std()))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Run #0:\n",
      "Loaded data\n",
      "Built model\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 98, 64)            1216      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 98, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 98, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 49, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 23, 256)           82176     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 23, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 23, 256)           0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d (AveragePo (None, 11, 256)           0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 256)               0         \n",
      "=================================================================\n",
      "Total params: 84,672\n",
      "Trainable params: 84,032\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Start training ...\n",
      "Epoch 1/100\n",
      "1500/1500 - 16s - loss: 0.1524 - accuracy: 0.9523 - val_loss: 0.1235 - val_accuracy: 0.9583\n",
      "Epoch 2/100\n",
      "1500/1500 - 9s - loss: 0.0696 - accuracy: 0.9792 - val_loss: 0.0988 - val_accuracy: 0.9679\n",
      "Epoch 3/100\n",
      "1500/1500 - 9s - loss: 0.0476 - accuracy: 0.9860 - val_loss: 0.1091 - val_accuracy: 0.9633\n",
      "Epoch 4/100\n",
      "1500/1500 - 9s - loss: 0.0356 - accuracy: 0.9898 - val_loss: 0.1148 - val_accuracy: 0.9681\n",
      "Epoch 5/100\n",
      "1500/1500 - 9s - loss: 0.0261 - accuracy: 0.9920 - val_loss: 0.0586 - val_accuracy: 0.9812\n",
      "Epoch 6/100\n",
      "1500/1500 - 9s - loss: 0.0235 - accuracy: 0.9930 - val_loss: 0.0729 - val_accuracy: 0.9765\n",
      "Epoch 7/100\n",
      "1500/1500 - 9s - loss: 0.0185 - accuracy: 0.9946 - val_loss: 0.0770 - val_accuracy: 0.9750\n",
      "Epoch 8/100\n",
      "1500/1500 - 9s - loss: 0.0161 - accuracy: 0.9956 - val_loss: 0.0643 - val_accuracy: 0.9823\n",
      "Epoch 9/100\n",
      "1500/1500 - 10s - loss: 0.0155 - accuracy: 0.9955 - val_loss: 0.1207 - val_accuracy: 0.9712\n",
      "Epoch 10/100\n",
      "1500/1500 - 9s - loss: 0.0135 - accuracy: 0.9959 - val_loss: 0.1442 - val_accuracy: 0.9683\n",
      "Epoch 11/100\n",
      "1500/1500 - 9s - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.0964 - val_accuracy: 0.9754\n",
      "Epoch 12/100\n",
      "1500/1500 - 9s - loss: 0.0117 - accuracy: 0.9965 - val_loss: 0.1756 - val_accuracy: 0.9654\n",
      "Epoch 13/100\n",
      "1500/1500 - 9s - loss: 0.0117 - accuracy: 0.9966 - val_loss: 0.0938 - val_accuracy: 0.9721\n",
      "Finished training\n",
      "Saved model\n",
      "Siamese EER: 0.11083333333333334\n",
      "Siamese Accuracy: 0.8889583333333333\n",
      "SVM Accuracy: 0.860625\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.5677 - acc: 0.8460\n",
      "ANN Accuracy: 0.8460416793823242\n",
      "KNN Accuracy: 0.9122916666666666\n",
      "Run #1:\n",
      "Loaded data\n",
      "Built model\n",
      "Start training ...\n",
      "Epoch 1/100\n",
      "1500/1500 - 9s - loss: 0.1472 - accuracy: 0.9547 - val_loss: 0.1501 - val_accuracy: 0.9504\n",
      "Epoch 2/100\n",
      "1500/1500 - 9s - loss: 0.0692 - accuracy: 0.9796 - val_loss: 0.1639 - val_accuracy: 0.9521\n",
      "Epoch 3/100\n",
      "1500/1500 - 9s - loss: 0.0478 - accuracy: 0.9862 - val_loss: 0.1254 - val_accuracy: 0.9688\n",
      "Epoch 4/100\n",
      "1500/1500 - 9s - loss: 0.0373 - accuracy: 0.9889 - val_loss: 0.2056 - val_accuracy: 0.9538\n",
      "Epoch 5/100\n",
      "1500/1500 - 9s - loss: 0.0294 - accuracy: 0.9917 - val_loss: 0.1301 - val_accuracy: 0.9706\n",
      "Epoch 6/100\n",
      "1500/1500 - 9s - loss: 0.0248 - accuracy: 0.9930 - val_loss: 0.1401 - val_accuracy: 0.9700\n",
      "Epoch 7/100\n",
      "1500/1500 - 9s - loss: 0.0215 - accuracy: 0.9938 - val_loss: 0.1118 - val_accuracy: 0.9746\n",
      "Epoch 8/100\n",
      "1500/1500 - 9s - loss: 0.0190 - accuracy: 0.9945 - val_loss: 0.1543 - val_accuracy: 0.9679\n",
      "Epoch 9/100\n",
      "1500/1500 - 9s - loss: 0.0170 - accuracy: 0.9952 - val_loss: 0.1414 - val_accuracy: 0.9685\n",
      "Epoch 10/100\n",
      "1500/1500 - 9s - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.1321 - val_accuracy: 0.9760\n",
      "Epoch 11/100\n",
      "1500/1500 - 9s - loss: 0.0134 - accuracy: 0.9960 - val_loss: 0.1379 - val_accuracy: 0.9663\n",
      "Epoch 12/100\n",
      "1500/1500 - 8s - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.1291 - val_accuracy: 0.9719\n",
      "Epoch 13/100\n",
      "1500/1500 - 9s - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.1596 - val_accuracy: 0.9752\n",
      "Epoch 14/100\n",
      "1500/1500 - 8s - loss: 0.0097 - accuracy: 0.9971 - val_loss: 0.1646 - val_accuracy: 0.9688\n",
      "Epoch 15/100\n",
      "1500/1500 - 9s - loss: 0.0094 - accuracy: 0.9973 - val_loss: 0.1592 - val_accuracy: 0.9683\n",
      "Finished training\n",
      "Saved model\n",
      "Siamese EER: 0.06666666666666667\n",
      "Siamese Accuracy: 0.933125\n",
      "SVM Accuracy: 0.9016666666666666\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 1.2477 - acc: 0.8844\n",
      "ANN Accuracy: 0.8843749761581421\n",
      "KNN Accuracy: 0.9260416666666667\n",
      "Run #2:\n",
      "Loaded data\n",
      "Built model\n",
      "Start training ...\n",
      "Epoch 1/100\n",
      "1500/1500 - 10s - loss: 0.1359 - accuracy: 0.9580 - val_loss: 0.3065 - val_accuracy: 0.8963\n",
      "Epoch 2/100\n",
      "1500/1500 - 9s - loss: 0.0636 - accuracy: 0.9807 - val_loss: 0.3018 - val_accuracy: 0.9050\n",
      "Epoch 3/100\n",
      "1500/1500 - 9s - loss: 0.0431 - accuracy: 0.9873 - val_loss: 0.3868 - val_accuracy: 0.8956\n",
      "Epoch 4/100\n",
      "1500/1500 - 9s - loss: 0.0346 - accuracy: 0.9899 - val_loss: 0.3789 - val_accuracy: 0.8963\n",
      "Epoch 5/100\n",
      "1500/1500 - 9s - loss: 0.0274 - accuracy: 0.9918 - val_loss: 0.3976 - val_accuracy: 0.9052\n",
      "Epoch 6/100\n",
      "1500/1500 - 9s - loss: 0.0240 - accuracy: 0.9929 - val_loss: 0.3601 - val_accuracy: 0.9054\n",
      "Epoch 7/100\n",
      "1500/1500 - 9s - loss: 0.0201 - accuracy: 0.9941 - val_loss: 0.3811 - val_accuracy: 0.8990\n",
      "Epoch 8/100\n",
      "1500/1500 - 9s - loss: 0.0173 - accuracy: 0.9949 - val_loss: 0.3532 - val_accuracy: 0.9131\n",
      "Epoch 9/100\n",
      "1500/1500 - 9s - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.4006 - val_accuracy: 0.8919\n",
      "Epoch 10/100\n",
      "1500/1500 - 9s - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.3544 - val_accuracy: 0.9062\n",
      "Epoch 11/100\n",
      "1500/1500 - 9s - loss: 0.0127 - accuracy: 0.9961 - val_loss: 0.3939 - val_accuracy: 0.9035\n",
      "Epoch 12/100\n",
      "1500/1500 - 9s - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.2627 - val_accuracy: 0.9187\n",
      "Epoch 13/100\n",
      "1500/1500 - 9s - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.3274 - val_accuracy: 0.8975\n",
      "Epoch 14/100\n",
      "1500/1500 - 9s - loss: 0.0093 - accuracy: 0.9974 - val_loss: 0.4820 - val_accuracy: 0.9108\n",
      "Epoch 15/100\n",
      "1500/1500 - 9s - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.2992 - val_accuracy: 0.9246\n",
      "Epoch 16/100\n",
      "1500/1500 - 9s - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.2868 - val_accuracy: 0.9212\n",
      "Epoch 17/100\n",
      "1500/1500 - 9s - loss: 0.0085 - accuracy: 0.9975 - val_loss: 0.5366 - val_accuracy: 0.8823\n",
      "Epoch 18/100\n",
      "1500/1500 - 9s - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.5920 - val_accuracy: 0.8888\n",
      "Epoch 19/100\n",
      "1500/1500 - 9s - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.3581 - val_accuracy: 0.9185\n",
      "Epoch 20/100\n",
      "1500/1500 - 9s - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.3076 - val_accuracy: 0.9137\n",
      "Finished training\n",
      "Saved model\n",
      "Siamese EER: 0.0975\n",
      "Siamese Accuracy: 0.9025\n",
      "SVM Accuracy: 0.8783333333333333\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 3.5331 - acc: 0.8798\n",
      "ANN Accuracy: 0.8797916769981384\n",
      "KNN Accuracy: 0.855625\n",
      "Run #3:\n",
      "Loaded data\n",
      "Built model\n",
      "Start training ...\n",
      "Epoch 1/100\n",
      "1500/1500 - 11s - loss: 0.1492 - accuracy: 0.9539 - val_loss: 0.2057 - val_accuracy: 0.9269\n",
      "Epoch 2/100\n",
      "1500/1500 - 9s - loss: 0.0687 - accuracy: 0.9797 - val_loss: 0.2029 - val_accuracy: 0.9185\n",
      "Epoch 3/100\n",
      "1500/1500 - 10s - loss: 0.0491 - accuracy: 0.9854 - val_loss: 0.1703 - val_accuracy: 0.9315\n",
      "Epoch 4/100\n",
      "1500/1500 - 9s - loss: 0.0348 - accuracy: 0.9899 - val_loss: 0.2455 - val_accuracy: 0.9235\n",
      "Epoch 5/100\n",
      "1500/1500 - 9s - loss: 0.0303 - accuracy: 0.9910 - val_loss: 0.2105 - val_accuracy: 0.9304\n",
      "Epoch 6/100\n",
      "1500/1500 - 9s - loss: 0.0238 - accuracy: 0.9933 - val_loss: 0.1205 - val_accuracy: 0.9525\n",
      "Epoch 7/100\n",
      "1500/1500 - 9s - loss: 0.0221 - accuracy: 0.9934 - val_loss: 0.2322 - val_accuracy: 0.9285\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 8/100\n",
      "1500/1500 - 10s - loss: 0.0174 - accuracy: 0.9952 - val_loss: 0.1691 - val_accuracy: 0.9442\n",
      "Epoch 9/100\n",
      "1500/1500 - 9s - loss: 0.0164 - accuracy: 0.9953 - val_loss: 0.1932 - val_accuracy: 0.9519\n",
      "Epoch 10/100\n",
      "1500/1500 - 9s - loss: 0.0138 - accuracy: 0.9960 - val_loss: 0.2614 - val_accuracy: 0.9373\n",
      "Epoch 11/100\n",
      "1500/1500 - 9s - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.1892 - val_accuracy: 0.9454\n",
      "Finished training\n",
      "Saved model\n",
      "Siamese EER: 0.04875\n",
      "Siamese Accuracy: 0.9510416666666667\n",
      "SVM Accuracy: 0.9529166666666666\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 1.9583 - acc: 0.9169\n",
      "ANN Accuracy: 0.9168750047683716\n",
      "KNN Accuracy: 0.9404166666666667\n",
      "Run #4:\n",
      "Loaded data\n",
      "Built model\n",
      "Start training ...\n",
      "Epoch 1/100\n",
      "1500/1500 - 10s - loss: 0.1501 - accuracy: 0.9523 - val_loss: 0.1710 - val_accuracy: 0.9421\n",
      "Epoch 2/100\n",
      "1500/1500 - 9s - loss: 0.0690 - accuracy: 0.9793 - val_loss: 0.2280 - val_accuracy: 0.9194\n",
      "Epoch 3/100\n",
      "1500/1500 - 9s - loss: 0.0459 - accuracy: 0.9863 - val_loss: 0.1985 - val_accuracy: 0.9331\n",
      "Epoch 4/100\n",
      "1500/1500 - 9s - loss: 0.0348 - accuracy: 0.9897 - val_loss: 0.2730 - val_accuracy: 0.9210\n",
      "Epoch 5/100\n",
      "1500/1500 - 9s - loss: 0.0272 - accuracy: 0.9923 - val_loss: 0.1933 - val_accuracy: 0.9413\n",
      "Epoch 6/100\n",
      "1500/1500 - 9s - loss: 0.0222 - accuracy: 0.9938 - val_loss: 0.2537 - val_accuracy: 0.9304\n",
      "Finished training\n",
      "Saved model\n",
      "Siamese EER: 0.07166666666666667\n",
      "Siamese Accuracy: 0.9279166666666666\n",
      "SVM Accuracy: 0.9229166666666667\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 1.3152 - acc: 0.9281\n",
      "ANN Accuracy: 0.9281250238418579\n",
      "KNN Accuracy: 0.92875\n",
      "Run #5:\n",
      "Loaded data\n",
      "Built model\n",
      "Start training ...\n",
      "Epoch 1/100\n",
      "1500/1500 - 10s - loss: 0.1418 - accuracy: 0.9557 - val_loss: 0.2002 - val_accuracy: 0.9394\n",
      "Epoch 2/100\n",
      "1500/1500 - 9s - loss: 0.0618 - accuracy: 0.9820 - val_loss: 0.2688 - val_accuracy: 0.9302\n",
      "Epoch 3/100\n",
      "1500/1500 - 9s - loss: 0.0420 - accuracy: 0.9880 - val_loss: 0.2043 - val_accuracy: 0.9325\n",
      "Epoch 4/100\n",
      "1500/1500 - 8s - loss: 0.0322 - accuracy: 0.9907 - val_loss: 0.3304 - val_accuracy: 0.9254\n",
      "Epoch 5/100\n",
      "1500/1500 - 9s - loss: 0.0260 - accuracy: 0.9925 - val_loss: 0.1952 - val_accuracy: 0.9371\n",
      "Epoch 6/100\n",
      "1500/1500 - 8s - loss: 0.0207 - accuracy: 0.9941 - val_loss: 0.2202 - val_accuracy: 0.9415\n",
      "Epoch 7/100\n",
      "1500/1500 - 8s - loss: 0.0180 - accuracy: 0.9949 - val_loss: 0.3302 - val_accuracy: 0.9379\n",
      "Epoch 8/100\n",
      "1500/1500 - 8s - loss: 0.0151 - accuracy: 0.9957 - val_loss: 0.3185 - val_accuracy: 0.9365\n",
      "Epoch 9/100\n",
      "1500/1500 - 8s - loss: 0.0133 - accuracy: 0.9961 - val_loss: 0.3694 - val_accuracy: 0.9277\n",
      "Epoch 10/100\n",
      "1500/1500 - 9s - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.4110 - val_accuracy: 0.9250\n",
      "Epoch 11/100\n",
      "1500/1500 - 9s - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.4582 - val_accuracy: 0.9269\n",
      "Finished training\n",
      "Saved model\n",
      "Siamese EER: 0.051666666666666666\n",
      "Siamese Accuracy: 0.948125\n",
      "SVM Accuracy: 0.9164583333333334\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 2.3375 - acc: 0.8946\n",
      "ANN Accuracy: 0.8945833444595337\n",
      "KNN Accuracy: 0.9329166666666666\n",
      "Run #6:\n",
      "Loaded data\n",
      "Built model\n",
      "Start training ...\n",
      "Epoch 1/100\n",
      "1500/1500 - 10s - loss: 0.1396 - accuracy: 0.9570 - val_loss: 0.3388 - val_accuracy: 0.8827\n",
      "Epoch 2/100\n",
      "1500/1500 - 9s - loss: 0.0649 - accuracy: 0.9806 - val_loss: 0.3570 - val_accuracy: 0.8938\n",
      "Epoch 3/100\n",
      "1500/1500 - 9s - loss: 0.0437 - accuracy: 0.9875 - val_loss: 0.3733 - val_accuracy: 0.8769\n",
      "Epoch 4/100\n",
      "1500/1500 - 9s - loss: 0.0338 - accuracy: 0.9898 - val_loss: 0.3763 - val_accuracy: 0.8948\n",
      "Epoch 5/100\n",
      "1500/1500 - 9s - loss: 0.0272 - accuracy: 0.9920 - val_loss: 0.5253 - val_accuracy: 0.8850\n",
      "Epoch 6/100\n",
      "1500/1500 - 9s - loss: 0.0215 - accuracy: 0.9937 - val_loss: 0.4128 - val_accuracy: 0.8873\n",
      "Epoch 7/100\n",
      "1500/1500 - 9s - loss: 0.0184 - accuracy: 0.9947 - val_loss: 0.3839 - val_accuracy: 0.8833\n",
      "Epoch 8/100\n",
      "1500/1500 - 9s - loss: 0.0164 - accuracy: 0.9951 - val_loss: 0.5293 - val_accuracy: 0.8654\n",
      "Epoch 9/100\n",
      "1500/1500 - 9s - loss: 0.0142 - accuracy: 0.9958 - val_loss: 0.4005 - val_accuracy: 0.8963\n",
      "Epoch 10/100\n",
      "1500/1500 - 9s - loss: 0.0124 - accuracy: 0.9964 - val_loss: 0.4142 - val_accuracy: 0.8913\n",
      "Epoch 11/100\n",
      "1500/1500 - 9s - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.3902 - val_accuracy: 0.8925\n",
      "Epoch 12/100\n",
      "1500/1500 - 9s - loss: 0.0115 - accuracy: 0.9966 - val_loss: 0.3666 - val_accuracy: 0.9000\n",
      "Epoch 13/100\n",
      "1500/1500 - 9s - loss: 0.0094 - accuracy: 0.9973 - val_loss: 0.5963 - val_accuracy: 0.8763\n",
      "Epoch 14/100\n",
      "1500/1500 - 9s - loss: 0.0090 - accuracy: 0.9975 - val_loss: 0.4075 - val_accuracy: 0.9002\n",
      "Epoch 15/100\n",
      "1500/1500 - 9s - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.4252 - val_accuracy: 0.8935\n",
      "Epoch 16/100\n",
      "1500/1500 - 9s - loss: 0.0095 - accuracy: 0.9972 - val_loss: 0.4729 - val_accuracy: 0.8913\n",
      "Epoch 17/100\n",
      "1500/1500 - 8s - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.5397 - val_accuracy: 0.8842\n",
      "Epoch 18/100\n",
      "1500/1500 - 9s - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.6130 - val_accuracy: 0.8710\n",
      "Epoch 19/100\n",
      "1500/1500 - 9s - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.4255 - val_accuracy: 0.8929\n",
      "Finished training\n",
      "Saved model\n",
      "Siamese EER: 0.08125\n",
      "Siamese Accuracy: 0.9185416666666667\n",
      "SVM Accuracy: 0.8733333333333333\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 3.1755 - acc: 0.8725\n",
      "ANN Accuracy: 0.8725000023841858\n",
      "KNN Accuracy: 0.8385416666666666\n",
      "Run #7:\n",
      "Loaded data\n",
      "Built model\n",
      "Start training ...\n",
      "Epoch 1/100\n",
      "1500/1500 - 11s - loss: 0.1519 - accuracy: 0.9520 - val_loss: 0.4313 - val_accuracy: 0.8888\n",
      "Epoch 2/100\n",
      "1500/1500 - 9s - loss: 0.0688 - accuracy: 0.9793 - val_loss: 0.3799 - val_accuracy: 0.8944\n",
      "Epoch 3/100\n",
      "1500/1500 - 9s - loss: 0.0477 - accuracy: 0.9862 - val_loss: 0.3519 - val_accuracy: 0.9038\n",
      "Epoch 4/100\n",
      "1500/1500 - 9s - loss: 0.0354 - accuracy: 0.9895 - val_loss: 0.4289 - val_accuracy: 0.8985\n",
      "Epoch 5/100\n",
      "1500/1500 - 9s - loss: 0.0278 - accuracy: 0.9915 - val_loss: 0.3491 - val_accuracy: 0.9127\n",
      "Epoch 6/100\n",
      "1500/1500 - 9s - loss: 0.0223 - accuracy: 0.9936 - val_loss: 0.4549 - val_accuracy: 0.8954\n",
      "Epoch 7/100\n",
      "1500/1500 - 9s - loss: 0.0200 - accuracy: 0.9942 - val_loss: 0.3678 - val_accuracy: 0.9129\n",
      "Epoch 8/100\n",
      "1500/1500 - 9s - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.3343 - val_accuracy: 0.9198\n",
      "Epoch 9/100\n",
      "1500/1500 - 9s - loss: 0.0150 - accuracy: 0.9959 - val_loss: 0.4038 - val_accuracy: 0.8821\n",
      "Epoch 10/100\n",
      "1500/1500 - 9s - loss: 0.0134 - accuracy: 0.9962 - val_loss: 0.5102 - val_accuracy: 0.9115\n",
      "Epoch 11/100\n",
      "1500/1500 - 9s - loss: 0.0140 - accuracy: 0.9960 - val_loss: 0.4407 - val_accuracy: 0.8985\n",
      "Epoch 12/100\n",
      "1500/1500 - 9s - loss: 0.0110 - accuracy: 0.9967 - val_loss: 0.4471 - val_accuracy: 0.9083\n",
      "Epoch 13/100\n",
      "1500/1500 - 9s - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.3357 - val_accuracy: 0.9225\n",
      "Epoch 14/100\n",
      "1500/1500 - 9s - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.4411 - val_accuracy: 0.9144\n",
      "Epoch 15/100\n",
      "1500/1500 - 9s - loss: 0.0092 - accuracy: 0.9973 - val_loss: 0.3198 - val_accuracy: 0.9185\n",
      "Epoch 16/100\n",
      "1500/1500 - 9s - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.4731 - val_accuracy: 0.9052\n",
      "Epoch 17/100\n",
      "1500/1500 - 9s - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.4120 - val_accuracy: 0.9083\n",
      "Epoch 18/100\n",
      "1500/1500 - 9s - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.5606 - val_accuracy: 0.9123\n",
      "Finished training\n",
      "Saved model\n",
      "Siamese EER: 0.09583333333333334\n",
      "Siamese Accuracy: 0.9041666666666667\n",
      "SVM Accuracy: 0.9070833333333334\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 3.2095 - acc: 0.8900\n",
      "ANN Accuracy: 0.8899999856948853\n",
      "KNN Accuracy: 0.91\n",
      "Run #8:\n",
      "Loaded data\n",
      "Built model\n",
      "Start training ...\n",
      "Epoch 1/100\n",
      "1500/1500 - 10s - loss: 0.1503 - accuracy: 0.9535 - val_loss: 0.2195 - val_accuracy: 0.9167\n",
      "Epoch 2/100\n",
      "1500/1500 - 9s - loss: 0.0685 - accuracy: 0.9797 - val_loss: 0.2121 - val_accuracy: 0.9104\n",
      "Epoch 3/100\n",
      "1500/1500 - 9s - loss: 0.0491 - accuracy: 0.9854 - val_loss: 0.2830 - val_accuracy: 0.9142\n",
      "Epoch 4/100\n",
      "1500/1500 - 9s - loss: 0.0376 - accuracy: 0.9890 - val_loss: 0.2196 - val_accuracy: 0.9237\n",
      "Epoch 5/100\n",
      "1500/1500 - 9s - loss: 0.0291 - accuracy: 0.9912 - val_loss: 0.2629 - val_accuracy: 0.9271\n",
      "Epoch 6/100\n",
      "1500/1500 - 9s - loss: 0.0262 - accuracy: 0.9923 - val_loss: 0.2838 - val_accuracy: 0.9212\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 7/100\n",
      "1500/1500 - 9s - loss: 0.0199 - accuracy: 0.9942 - val_loss: 0.2172 - val_accuracy: 0.9296\n",
      "Epoch 8/100\n",
      "1500/1500 - 9s - loss: 0.0192 - accuracy: 0.9941 - val_loss: 0.2179 - val_accuracy: 0.9290\n",
      "Epoch 9/100\n",
      "1500/1500 - 9s - loss: 0.0155 - accuracy: 0.9955 - val_loss: 0.3005 - val_accuracy: 0.9254\n",
      "Epoch 10/100\n",
      "1500/1500 - 9s - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.3977 - val_accuracy: 0.9152\n",
      "Epoch 11/100\n",
      "1500/1500 - 9s - loss: 0.0132 - accuracy: 0.9961 - val_loss: 0.3349 - val_accuracy: 0.9233\n",
      "Epoch 12/100\n",
      "1500/1500 - 9s - loss: 0.0125 - accuracy: 0.9966 - val_loss: 0.3974 - val_accuracy: 0.9106\n",
      "Finished training\n",
      "Saved model\n",
      "Siamese EER: 0.04375\n",
      "Siamese Accuracy: 0.9560416666666667\n",
      "SVM Accuracy: 0.9141666666666667\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 1.0946 - acc: 0.8917\n",
      "ANN Accuracy: 0.8916666507720947\n",
      "KNN Accuracy: 0.9495833333333333\n",
      "Run #9:\n",
      "Loaded data\n",
      "Built model\n",
      "Start training ...\n",
      "Epoch 1/100\n",
      "1500/1500 - 10s - loss: 0.1518 - accuracy: 0.9515 - val_loss: 0.1467 - val_accuracy: 0.9523\n",
      "Epoch 2/100\n",
      "1500/1500 - 9s - loss: 0.0698 - accuracy: 0.9790 - val_loss: 0.1416 - val_accuracy: 0.9538\n",
      "Epoch 3/100\n",
      "1500/1500 - 9s - loss: 0.0487 - accuracy: 0.9856 - val_loss: 0.1424 - val_accuracy: 0.9515\n",
      "Epoch 4/100\n",
      "1500/1500 - 9s - loss: 0.0373 - accuracy: 0.9890 - val_loss: 0.1635 - val_accuracy: 0.9452\n",
      "Epoch 5/100\n",
      "1500/1500 - 9s - loss: 0.0294 - accuracy: 0.9914 - val_loss: 0.1312 - val_accuracy: 0.9519\n",
      "Epoch 6/100\n",
      "1500/1500 - 9s - loss: 0.0228 - accuracy: 0.9936 - val_loss: 0.1270 - val_accuracy: 0.9517\n",
      "Epoch 7/100\n",
      "1500/1500 - 9s - loss: 0.0197 - accuracy: 0.9944 - val_loss: 0.1332 - val_accuracy: 0.9565\n",
      "Epoch 8/100\n",
      "1500/1500 - 10s - loss: 0.0188 - accuracy: 0.9945 - val_loss: 0.1250 - val_accuracy: 0.9554\n",
      "Epoch 9/100\n",
      "1500/1500 - 9s - loss: 0.0144 - accuracy: 0.9959 - val_loss: 0.1404 - val_accuracy: 0.9608\n",
      "Epoch 10/100\n",
      "1500/1500 - 9s - loss: 0.0153 - accuracy: 0.9954 - val_loss: 0.1351 - val_accuracy: 0.9606\n",
      "Epoch 11/100\n",
      "1500/1500 - 9s - loss: 0.0116 - accuracy: 0.9967 - val_loss: 0.1444 - val_accuracy: 0.9550\n",
      "Epoch 12/100\n",
      "1500/1500 - 9s - loss: 0.0115 - accuracy: 0.9967 - val_loss: 0.1340 - val_accuracy: 0.9596\n",
      "Epoch 13/100\n",
      "1500/1500 - 9s - loss: 0.0113 - accuracy: 0.9968 - val_loss: 0.1286 - val_accuracy: 0.9563\n",
      "Epoch 14/100\n",
      "1500/1500 - 10s - loss: 0.0098 - accuracy: 0.9971 - val_loss: 0.1559 - val_accuracy: 0.9517\n",
      "Finished training\n",
      "Saved model\n",
      "Siamese EER: 0.05416666666666667\n",
      "Siamese Accuracy: 0.9458333333333333\n",
      "SVM Accuracy: 0.9464583333333333\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 1.0855 - acc: 0.9421\n",
      "ANN Accuracy: 0.9420833587646484\n",
      "KNN Accuracy: 0.935\n",
      "[0.889  0.9331 0.9025 0.951  0.9279 0.9481 0.9185 0.9042 0.956  0.9458]\n",
      "siamese accuracy: 0.9276250000000001 +/- 0.022129511467219018\n",
      "[0.8606 0.9017 0.8783 0.9529 0.9229 0.9165 0.8733 0.9071 0.9142 0.9465]\n",
      "svm accuracy: 0.9073958333333334 +/- 0.028622035569450498\n",
      "[0.846  0.8844 0.8798 0.9169 0.9281 0.8946 0.8725 0.89   0.8917 0.9421]\n",
      "ann accuracy: 0.8946041703224182 +/- 0.0265982990657555\n",
      "[0.9123 0.926  0.8556 0.9404 0.9287 0.9329 0.8385 0.91   0.9496 0.935 ]\n",
      "knn accuracy: 0.9129166666666666 +/- 0.03497742327400476\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hiy6B7cuTFxm",
    "outputId": "0d3b8a68-833f-49db-8694-01d1d4aa6146"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "adam = Adam(learning_rate=0.001)\n",
    "cnn = build_model5(left_shape, bn=1, reg=0)\n",
    "siamese = models.build_siamese(left_shape, cnn, 0.1)\n",
    "siamese.compile(loss='binary_crossentropy', optimizer=adam, metrics=[BinaryAccuracy(name='accuracy')])\n",
    "siamese.load_weights(os.path.join(results_path, 'osaka', 'model_r{}_weights.h5'.format(0)))"
   ],
   "outputs": [],
   "metadata": {
    "id": "WDLnLi2nhjDC"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "print('Siamese network direct test accuracy:')\n",
    "siamese.evaluate([l_input_test, r_input_test], b_labels_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Siamese network direct test accuracy:\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-6e0bb9ec55de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Siamese network direct test accuracy:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msiamese\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml_input_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_input_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_labels_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'l_input_test' is not defined"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "68zo_lIziFii",
    "outputId": "b6a9d60a-7cf9-41bd-b676-6b2cfdc0991e"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "print('Siamese network direct test accuracy:')\n",
    "siamese.evaluate([l_input_test, r_input_test], b_labels_test)\n",
    "\n",
    "print('==========SVM==========')\n",
    "classifier = SVC(kernel='poly', degree=10, C=100)\n",
    "feature_exctractor = Model(inputs=[siamese.get_layer('left_input').input,siamese.get_layer('right_input').input], outputs=siamese.get_layer('lambda').output)\n",
    "d_vect = feature_exctractor.predict([l_input, r_input])\n",
    "d_vect_test = feature_exctractor.predict([l_input_test, r_input_test])\n",
    "print(d_vect.shape)\n",
    "\n",
    "classifier.fit(d_vect, b_labels)\n",
    "svc_score = classifier.score(d_vect_test, b_labels_test)\n",
    "print('SVC mean test accuracy:', svc_score*100)\n",
    "\n",
    "pca = PCA(2)\n",
    "colors = ['#800000',\n",
    "          '#bfef45']\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(121)\n",
    "plt.title('Ground Truth')\n",
    "d_vect_test_2d = pca.fit_transform(d_vect_test)\n",
    "plt.scatter(d_vect_test_2d[:, 0], d_vect_test_2d[:, 1], c=[colors[i] for i in b_labels_test], alpha=0.2)\n",
    "plt.subplot(122)\n",
    "plt.title('Prediction')\n",
    "d_vect_test_2d = pca.fit_transform(d_vect_test)\n",
    "plt.scatter(d_vect_test_2d[:, 0], d_vect_test_2d[:, 1], c=[colors[i] for i in classifier.predict(d_vect_test)], alpha=0.2)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# # print('==========OneClassSVM==========')\n",
    "\n",
    "# # outlier_detector = OneClassSVM(kernel='rbf')\n",
    "# # outlier_detector.fit(d_vect, b_labels)\n",
    "# # test_predictions = np.uint8(outlier_detector.predict(d_vect_test) > 0)\n",
    "# # svc_score = (test_predictions == b_labels_test).mean() * 100\n",
    "# # print('OneClassSVM mean test accuracy:', svc_score)\n",
    "\n",
    "# # pca = PCA(2)\n",
    "# # colors = ['#800000',\n",
    "# #           '#bfef45']\n",
    "# # plt.figure(figsize=(16,6))\n",
    "# # plt.subplot(121)\n",
    "# # plt.title('Ground Truth')\n",
    "# # d_vect_test_2d = pca.fit_transform(d_vect_test)\n",
    "# # plt.scatter(d_vect_test_2d[:, 0], d_vect_test_2d[:, 1], c=[colors[i] for i in b_labels_test], alpha=0.2)\n",
    "# # plt.subplot(122)\n",
    "# # plt.title('Prediction')\n",
    "# # d_vect_test_2d = pca.fit_transform(d_vect_test)\n",
    "# # plt.scatter(d_vect_test_2d[:, 0], d_vect_test_2d[:, 1], c=[colors[i] for i in test_predictions], alpha=0.2)\n",
    "# # plt.show()\n",
    "\n",
    "# print('==========ANN==========')\n",
    "\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# classifier = Sequential()\n",
    "# classifier.add(Dense(8, activation='relu', input_shape=(64,)))\n",
    "# classifier.add(Dropout(0.3))\n",
    "# classifier.add(Dense(8, activation='relu'))\n",
    "# classifier.add(Dropout(0.3))\n",
    "# classifier.add(Dense(1, activation='sigmoid'))\n",
    "# classifier.compile(loss='binary_crossentropy', metrics=['acc'], optimizer='adam')\n",
    "# classifier.fit(d_vect, b_labels, verbose=0, epochs=20, batch_size=128)\n",
    "# test_predictions = np.uint8(np.squeeze(classifier.predict(d_vect_test) >= 0.5))\n",
    "# # print(test_predictions[:10])\n",
    "# ann_score = classifier.evaluate(d_vect_test, b_labels_test)[1]\n",
    "# print('ANN mean test accuracy:', ann_score*100)\n",
    "\n",
    "# pca = PCA(2)\n",
    "# colors = ['#800000',\n",
    "#           '#bfef45']\n",
    "# plt.figure(figsize=(16,6))\n",
    "# plt.subplot(121)\n",
    "# plt.title('Ground Truth')\n",
    "# d_vect_test_2d = pca.fit_transform(d_vect_test)\n",
    "# plt.scatter(d_vect_test_2d[:, 0], d_vect_test_2d[:, 1], c=[colors[i] for i in b_labels_test], alpha=0.2)\n",
    "# plt.subplot(122)\n",
    "# plt.title('Prediction')\n",
    "# d_vect_test_2d = pca.fit_transform(d_vect_test)\n",
    "# plt.scatter(d_vect_test_2d[:, 0], d_vect_test_2d[:, 1], c=[colors[i] for i in test_predictions], alpha=0.2)\n",
    "# plt.show()\n",
    "\n",
    "# print('==========KNN==========')\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# knn = KNeighborsClassifier(n_neighbors=5)\n",
    "# knn.fit(d_vect, b_labels)\n",
    "# test_predictions = knn.predict(d_vect_test)\n",
    "# knn_score = knn.score(d_vect_test, b_labels_test)\n",
    "# print('KNN mean test accuracy:', knn_score*100)\n",
    "\n",
    "# pca = PCA(2)\n",
    "# colors = ['#800000',\n",
    "#           '#bfef45']\n",
    "# plt.figure(figsize=(16,6))\n",
    "# plt.subplot(121)\n",
    "# plt.title('Ground Truth')\n",
    "# d_vect_test_2d = pca.fit_transform(d_vect_test)\n",
    "# plt.scatter(d_vect_test_2d[:, 0], d_vect_test_2d[:, 1], c=[colors[i] for i in b_labels_test], alpha=0.2)\n",
    "# plt.subplot(122)\n",
    "# plt.title('Prediction')\n",
    "# d_vect_test_2d = pca.fit_transform(d_vect_test)\n",
    "# plt.scatter(d_vect_test_2d[:, 0], d_vect_test_2d[:, 1], c=[colors[i] for i in test_predictions], alpha=0.2)\n",
    "# plt.show()\n",
    "\n",
    "print('==========GaussionMixture==========')\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gmodel = GaussianMixture(n_components=5)\n",
    "gmodel.fit(d_vect, b_labels)\n",
    "test_predictions =  np.uint8((gmodel.score_samples(d_vect_test) > -55))\n",
    "print(test_predictions)\n",
    "gmodel_score = (test_predictions == b_labels_test).mean()\n",
    "print('Gaussian Mixture mean test accuracy:', gmodel_score*100)\n",
    "\n",
    "pca = PCA(2)\n",
    "colors = ['#800000',\n",
    "          '#bfef45']\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(121)\n",
    "plt.title('Ground Truth')\n",
    "d_vect_test_2d = pca.fit_transform(d_vect_test)\n",
    "plt.scatter(d_vect_test_2d[:, 0], d_vect_test_2d[:, 1], c=[colors[i] for i in b_labels_test], alpha=0.2)\n",
    "plt.subplot(122)\n",
    "plt.title('Prediction')\n",
    "d_vect_test_2d = pca.fit_transform(d_vect_test)\n",
    "plt.scatter(d_vect_test_2d[:, 0], d_vect_test_2d[:, 1], c=[colors[i] for i in test_predictions], alpha=0.2)\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "id": "iK0wUaUgTFxn"
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "osaka_cls_retrain.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}