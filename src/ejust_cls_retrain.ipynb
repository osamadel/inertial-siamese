{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Experiments"
   ],
   "metadata": {
    "id": "mvAor71-TFxU"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Roughly speaking, I will try to use the models trained on the datasets, then remove the FC layer and add other classifiers. Then I will report the result of the other classifiers on the final performance using either EER or accuracy."
   ],
   "metadata": {
    "id": "-DBFcSs6TFxe"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "data_path = '../data/ejust/'\n",
    "results_path = '../results/'\n",
    "\n",
    "# data_path = '/content/drive/MyDrive/IJCNN/data/osaka'\n",
    "# results_path = '/content/drive/MyDrive/IJCNN/results'"
   ],
   "outputs": [],
   "metadata": {
    "id": "cOPS399rTFxe"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OI-lQFRRKEAY",
    "outputId": "7e85a733-61b5-4742-a5c2-2ed5b6502d45"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "!cp -r \"/content/drive/MyDrive/IJCNN/src\" /content/\n",
    "!mv src/datasets.py datasets.py\n",
    "!mv src/models.py models.py\n",
    "!mv src/analyze.py analyze.py\n",
    "!ls"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "analyze.py  datasets.py  drive\tmodels.py  sample_data\tsrc\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jArT8WzDKPH2",
    "outputId": "e463a28e-25ed-4c96-870b-9cfec0a36b87"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import datasets, models, analyze\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import activations\n",
    "# from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "# import nevergrad as ng\n",
    "import os\n",
    "np.set_printoptions(precision=4)\n",
    "gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ],
   "outputs": [],
   "metadata": {
    "id": "k0TFGFVAKTNo"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ],
   "outputs": [],
   "metadata": {
    "id": "Qwqf4RGPJ08n"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def prepare_data(train_sps, val_sps, test_sps, max_cls, split, data, labels, indices_list, run_n):\n",
    "    train_split = int(split[0] * max_cls)\n",
    "    val_split = int(split[2] * max_cls)\n",
    "\n",
    "    rand_indices = np.random.choice(range(max_cls), size=max_cls, replace=False)\n",
    "    indices_list.append(rand_indices)\n",
    "    print('Run #%d:'%run_n)\n",
    "    \n",
    "    all_data_rand, all_labels_rand = [data[x] for x in rand_indices], [labels[x] for x in rand_indices]\n",
    "    b_data, b_labels = datasets.generate_batch(train_sps, all_data_rand[:train_split], all_labels_rand[:train_split])\n",
    "    \n",
    "    val_data, val_labels = datasets.generate_batch(val_sps, all_data_rand[train_split:train_split+val_split], all_labels_rand[train_split:train_split+val_split])\n",
    "    ridx = np.random.choice(range(b_data[0].shape[0]), size=b_data[0].shape[0], replace=False)\n",
    "    \n",
    "    b_data_test, b_labels_test = datasets.generate_batch(test_sps, all_data_rand[train_split+val_split:], all_labels_rand[train_split+val_split:])\n",
    "\n",
    "    l_input = b_data[0][ridx]\n",
    "    r_input = b_data[1][ridx]\n",
    "    b_labels = b_labels[ridx]\n",
    "\n",
    "    # print(l_input[0].shape)\n",
    "\n",
    "    l_input_val = val_data[0]\n",
    "    r_input_val = val_data[1]\n",
    "\n",
    "    l_input_test = b_data_test[0]\n",
    "    r_input_test = b_data_test[1]\n",
    "    return l_input, r_input, b_labels, l_input_val, r_input_val, val_labels, l_input_test, r_input_test, b_labels_test"
   ],
   "outputs": [],
   "metadata": {
    "id": "jvrnb1vgKVPf"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def load_dataset(segLen, overlap, acc_only):\n",
    "    data, labels = datasets.load_segment_EJUST(data_path, 'D5-LC', [0, 20], segment_time=2)\n",
    "    return data, labels"
   ],
   "outputs": [],
   "metadata": {
    "id": "JYx3YqoxK4PG"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def build_model1(input_shape, bn, reg):\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Conv1D, \\\n",
    "                                        MaxPooling1D, \\\n",
    "                                        AveragePooling1D, \\\n",
    "                                        Dense, Flatten, Dropout, \\\n",
    "                                        BatchNormalization, \\\n",
    "                                        GlobalMaxPooling1D, \\\n",
    "                                        GlobalAveragePooling1D, \\\n",
    "                                        Activation\n",
    "    from tensorflow.keras import activations\n",
    "    import tensorflow.keras.regularizers as regularizers\n",
    "\n",
    "    model = Sequential()\n",
    "    if reg:\n",
    "        model.add(Conv1D(16, 3, strides=1, input_shape=input_shape, \n",
    "                        kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                        bias_regularizer=regularizers.l2(1e-4)))\n",
    "    else:\n",
    "        model.add(Conv1D(16, 3, strides=1, input_shape=input_shape))\n",
    "    if bn:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Activation(activations.relu))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    if reg:\n",
    "        model.add(Conv1D(64, 5, strides=2, \n",
    "                        kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                        bias_regularizer=regularizers.l2(1e-4)))\n",
    "    else:\n",
    "        model.add(Conv1D(64, 5, strides=2))\n",
    "    if bn:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Activation(activations.relu))\n",
    "    model.add(AveragePooling1D(pool_size=2))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {
    "id": "-h4dUZV8WXlb"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "def build_model4(input_shape, bn, reg):\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Conv1D, \\\n",
    "                                        MaxPooling1D, \\\n",
    "                                        AveragePooling1D, \\\n",
    "                                        Dense, Flatten, Dropout, \\\n",
    "                                        BatchNormalization, \\\n",
    "                                        GlobalMaxPooling1D, \\\n",
    "                                        GlobalAveragePooling1D, \\\n",
    "                                        Activation\n",
    "    from tensorflow.keras import activations\n",
    "    import tensorflow.keras.regularizers as regularizers\n",
    "\n",
    "    model = Sequential()\n",
    "    if reg:\n",
    "        model.add(Conv1D(32, 3, strides=1, input_shape=input_shape, \n",
    "                        kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                        bias_regularizer=regularizers.l2(1e-4)))\n",
    "    else:\n",
    "        model.add(Conv1D(32, 3, strides=1, input_shape=input_shape))\n",
    "    if bn:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Activation(activations.relu))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    if reg:\n",
    "        model.add(Conv1D(128, 5, strides=2, \n",
    "                        kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                        bias_regularizer=regularizers.l2(1e-4)))\n",
    "    else:\n",
    "        model.add(Conv1D(128, 5, strides=2))\n",
    "    if bn:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Activation(activations.relu))\n",
    "    model.add(AveragePooling1D(pool_size=2))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {
    "id": "q7x9rfwDIqx-"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def build_model5(input_shape, bn, reg):\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Conv1D, \\\n",
    "                                        MaxPooling1D, \\\n",
    "                                        AveragePooling1D, \\\n",
    "                                        Dense, Flatten, Dropout, \\\n",
    "                                        BatchNormalization, \\\n",
    "                                        GlobalMaxPooling1D, \\\n",
    "                                        GlobalAveragePooling1D, \\\n",
    "                                        Activation\n",
    "    from tensorflow.keras import activations\n",
    "    import tensorflow.keras.regularizers as regularizers\n",
    "\n",
    "    model = Sequential()\n",
    "    if reg:\n",
    "        model.add(Conv1D(64, 3, strides=1, input_shape=input_shape, \n",
    "                        kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                        bias_regularizer=regularizers.l2(1e-4)))\n",
    "    else:\n",
    "        model.add(Conv1D(64, 3, strides=1, input_shape=input_shape))\n",
    "    if bn:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Activation(activations.relu))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    if reg:\n",
    "        model.add(Conv1D(256, 5, strides=2, \n",
    "                        kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                        bias_regularizer=regularizers.l2(1e-4)))\n",
    "    else:\n",
    "        model.add(Conv1D(256, 5, strides=2))\n",
    "    if bn:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Activation(activations.relu))\n",
    "    model.add(AveragePooling1D(pool_size=2))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {
    "id": "F28ig3xVIzuJ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "acc_only_list    = [False, True]\n",
    "segLen_list      = [1, 2]\n",
    "overlap_list     = [0, 0.25, 0.5, 0.75]\n",
    "# models_list      = [build_model1, build_model2, build_model3]\n",
    "models_list      = [build_model5]\n",
    "bn_list          = [True, False]\n",
    "reg_list         = [True, False]\n",
    "\n",
    "# Configurations\n",
    "train_sps       = 500\n",
    "val_sps         = 200\n",
    "test_sps        = 200\n",
    "max_cls         = 20\n",
    "split           = [0.5, 0.25, 0.25]\n",
    "output_dropout  = 0.1\n",
    "runs            = 10\n",
    "np.set_printoptions(precision=4)"
   ],
   "outputs": [],
   "metadata": {
    "id": "DFUOb5_GUo-e"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "def getSiameseAcc(siamese, test_set, EER_th):\n",
    "    # l_input_test, r_input_test = test_set[0]\n",
    "    b_labels_test = test_set[1]\n",
    "    # print('EER threshold:', EER_th)\n",
    "    # print(np.uint8(np.squeeze(siamese.predict(test_set[0])) >= EER_th))\n",
    "    # print(b_labels_test)\n",
    "    return np.mean(np.uint8(np.squeeze(siamese.predict(test_set[0])) >= EER_th) == b_labels_test)\n",
    "\n",
    "def trainSVM(siamese, training_set, test_set):\n",
    "    l_input, r_input = training_set[0]\n",
    "    b_labels = training_set[1]\n",
    "    l_input_test, r_input_test = test_set[0]\n",
    "    b_labels_test = test_set[1]\n",
    "\n",
    "    # classifier = SVC(kernel='poly', degree=10, C=100)\n",
    "    classifier = SVC(kernel='poly', degree=5, C=10)\n",
    "    feature_exctractor = Model(inputs=[siamese.get_layer('left_input').input,siamese.get_layer('right_input').input], outputs=siamese.get_layer('lambda').output)\n",
    "    d_vect = feature_exctractor.predict([l_input, r_input])\n",
    "    d_vect_test = feature_exctractor.predict([l_input_test, r_input_test])\n",
    "    \n",
    "    # print(d_vect.shape)\n",
    "\n",
    "    classifier.fit(d_vect, b_labels)\n",
    "    svc_score = classifier.score(d_vect_test, b_labels_test)\n",
    "    # print('SVC mean test accuracy:', svc_score*100)\n",
    "    return svc_score\n",
    "\n",
    "def trainKNN(siamese, training_set, test_set):\n",
    "    l_input, r_input = training_set[0]\n",
    "    b_labels = training_set[1]\n",
    "    l_input_test, r_input_test = test_set[0]\n",
    "    b_labels_test = test_set[1]\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    feature_exctractor = Model(inputs=[siamese.get_layer('left_input').input,siamese.get_layer('right_input').input], outputs=siamese.get_layer('lambda').output)\n",
    "    d_vect = feature_exctractor.predict([l_input, r_input])\n",
    "    d_vect_test = feature_exctractor.predict([l_input_test, r_input_test])\n",
    "\n",
    "    knn.fit(d_vect, b_labels)\n",
    "    test_predictions = knn.predict(d_vect_test)\n",
    "    knn_score = knn.score(d_vect_test, b_labels_test)\n",
    "    # print('KNN mean test accuracy:', knn_score*100)\n",
    "    return knn_score\n",
    "\n",
    "def trainANN(siamese, training_set, test_set):\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "    l_input, r_input = training_set[0]\n",
    "    b_labels = training_set[1]\n",
    "    l_input_test, r_input_test = test_set[0]\n",
    "    b_labels_test = test_set[1]\n",
    "\n",
    "    feature_exctractor = Model(inputs=[siamese.get_layer('left_input').input,siamese.get_layer('right_input').input], outputs=siamese.get_layer('lambda').output)\n",
    "    d_vect = feature_exctractor.predict([l_input, r_input])\n",
    "    d_vect_test = feature_exctractor.predict([l_input_test, r_input_test])\n",
    "\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(8, activation='relu', input_shape=(256,)))\n",
    "    classifier.add(Dropout(0.3))\n",
    "    classifier.add(Dense(8, activation='relu'))\n",
    "    classifier.add(Dropout(0.3))\n",
    "    classifier.add(Dense(1, activation='sigmoid'))\n",
    "    classifier.compile(loss='binary_crossentropy', metrics=['acc'], optimizer='adam')\n",
    "\n",
    "    classifier.fit(d_vect, b_labels, verbose=0, epochs=20, batch_size=128)\n",
    "    # test_predictions = np.uint8(np.squeeze(classifier.predict(d_vect_test) >= 0.5))\n",
    "    # print(test_predictions[:10])\n",
    "    ann_score = classifier.evaluate(d_vect_test, b_labels_test)[1]\n",
    "    # print('ANN mean test accuracy:', ann_score*100)\n",
    "    return ann_score"
   ],
   "outputs": [],
   "metadata": {
    "id": "CxkqRdMpDOip"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "def one_run(train_sps, val_sps, test_sps, max_cls, split, data, labels, lst, run_n):\n",
    "    accuracies = {}\n",
    "    l_input, r_input, b_labels \\\n",
    "        , l_input_val, r_input_val, val_labels \\\n",
    "            , l_input_test, r_input_test, b_labels_test = prepare_data( train_sps,\n",
    "                                                                        val_sps,\n",
    "                                                                        test_sps,\n",
    "                                                                        max_cls,\n",
    "                                                                        split,\n",
    "                                                                        data,\n",
    "                                                                        labels,\n",
    "                                                                        [],\n",
    "                                                                        run_n)\n",
    "    print('Loaded data')\n",
    "    adam = Adam(learning_rate=0.001)\n",
    "    earlystop = EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "    \n",
    "    cnn = build_model5(l_input[0].shape, bn=1, reg=0)\n",
    "    siamese = models.build_siamese(l_input[0].shape, cnn, output_dropout)\n",
    "    siamese.compile(loss='binary_crossentropy', optimizer=adam, metrics=[BinaryAccuracy(name='accuracy')])\n",
    "    print('Built model')\n",
    "    if run_n == 0: \n",
    "        cnn.summary()\n",
    "    print('Start training ...')\n",
    "    hist = siamese.fit([l_input, r_input], \n",
    "                        b_labels, \n",
    "                        shuffle=True,\n",
    "                        batch_size=64,\n",
    "                        epochs=100,\n",
    "                        callbacks=[earlystop],\n",
    "                        validation_data=([l_input_val, r_input_val], val_labels),\n",
    "                        verbose=2\n",
    "                        )\n",
    "    print('Finished training')\n",
    "    siamese.save_weights(os.path.join(results_path, 'ejust', 'model_r{}_weights.h5'.format(run_n)))\n",
    "    print('Saved model')\n",
    "    FRR, FAR, EER, EER_th = analyze.ROC(siamese, [l_input_test, r_input_test], b_labels_test)\n",
    "    print('Siamese EER:', EER)\n",
    "    accuracies['siamese'] = getSiameseAcc(siamese, ([l_input_test, r_input_test], b_labels_test), EER_th)\n",
    "    print('Siamese Accuracy:', accuracies['siamese'])\n",
    "    accuracies['svm'] = trainSVM(siamese, ([l_input, r_input], b_labels), ([l_input_test, r_input_test], b_labels_test))\n",
    "    print('SVM Accuracy:', accuracies['svm'])\n",
    "    accuracies['ann'] = trainANN(siamese, ([l_input, r_input], b_labels), ([l_input_test, r_input_test], b_labels_test))\n",
    "    print('ANN Accuracy:', accuracies['ann'])\n",
    "    accuracies['knn'] = trainKNN(siamese, ([l_input, r_input], b_labels), ([l_input_test, r_input_test], b_labels_test))\n",
    "    print('KNN Accuracy:', accuracies['knn'])\n",
    "\n",
    "\n",
    "    return siamese, [FRR, FAR, EER, EER_th], accuracies"
   ],
   "outputs": [],
   "metadata": {
    "id": "N-z-EqS3TFxl"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Experiment 1: Train Different Classifiers"
   ],
   "metadata": {
    "id": "B7TKW9MyTFxl"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "data, labels = load_dataset(2, 0, acc_only=False)\n",
    "num_cls = 4 # number of classifiers\n",
    "total_accs = np.zeros((runs, num_cls))\n",
    "\n",
    "# Results of this configuration/experiment\n",
    "# EERs = np.array([np.zeros(runs) for _ in range(3*2*2)])\n",
    "\n",
    "for run_n in range(runs):\n",
    "    siamese, ROC, accs = one_run(train_sps, val_sps, test_sps, max_cls, split, data, labels, [], run_n)\n",
    "    for ii, c in enumerate(accs):\n",
    "        total_accs[run_n, ii] = accs[c]\n",
    "    \n",
    "    np.save(os.path.join(results_path, 'ejust', 'classifiers.npy'), total_accs)\n",
    "    \n",
    "#     EERs[4 * model_index + 2*bn + reg , run_n] = EER\n",
    "#     np.save(results_path + 'osaka_filters_eers2.npy', EERs)\n",
    "\n",
    "for ii, c in enumerate(accs):\n",
    "    print(total_accs[:,ii])\n",
    "    print('{} accuracy: {} +/- {}'.format(c, total_accs[:,ii].mean(), total_accs[:,ii].std()))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Run #0:\n",
      "Loaded data\n",
      "Built model\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 98, 64)            1216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 98, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 98, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 49, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 23, 256)           82176     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 23, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 23, 256)           0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 11, 256)           0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 256)               0         \n",
      "=================================================================\n",
      "Total params: 84,672\n",
      "Trainable params: 84,032\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Start training ...\n",
      "Epoch 1/100\n",
      "157/157 - 3s - loss: 0.1654 - accuracy: 0.9544 - val_loss: 0.5811 - val_accuracy: 0.7715\n",
      "Epoch 2/100\n",
      "157/157 - 2s - loss: 0.0483 - accuracy: 0.9922 - val_loss: 0.6897 - val_accuracy: 0.7745\n",
      "Epoch 3/100\n",
      "157/157 - 1s - loss: 0.0202 - accuracy: 0.9988 - val_loss: 0.6999 - val_accuracy: 0.7860\n",
      "Epoch 4/100\n",
      "157/157 - 1s - loss: 0.0107 - accuracy: 0.9994 - val_loss: 0.7365 - val_accuracy: 0.7840\n",
      "Epoch 5/100\n",
      "157/157 - 1s - loss: 0.0095 - accuracy: 0.9992 - val_loss: 0.7419 - val_accuracy: 0.7870\n",
      "Epoch 6/100\n",
      "157/157 - 2s - loss: 0.0051 - accuracy: 0.9996 - val_loss: 0.9116 - val_accuracy: 0.7760\n",
      "Epoch 7/100\n",
      "157/157 - 2s - loss: 0.0101 - accuracy: 0.9985 - val_loss: 0.7765 - val_accuracy: 0.7800\n",
      "Epoch 8/100\n",
      "157/157 - 2s - loss: 0.0041 - accuracy: 0.9998 - val_loss: 0.9139 - val_accuracy: 0.7790\n",
      "Epoch 9/100\n",
      "157/157 - 2s - loss: 0.0027 - accuracy: 0.9999 - val_loss: 0.8893 - val_accuracy: 0.7865\n",
      "Epoch 10/100\n",
      "157/157 - 2s - loss: 0.0017 - accuracy: 0.9999 - val_loss: 1.0773 - val_accuracy: 0.7750\n",
      "Finished training\n",
      "Saved model\n",
      "Siamese EER: 0.133\n",
      "Siamese Accuracy: 0.867\n",
      "SVM Accuracy: 0.9255\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.7369 - acc: 0.8915\n",
      "ANN Accuracy: 0.8914999961853027\n",
      "KNN Accuracy: 0.929\n",
      "Run #1:\n",
      "Loaded data\n",
      "Built model\n",
      "Start training ...\n",
      "Epoch 1/100\n",
      "157/157 - 3s - loss: 0.2078 - accuracy: 0.9378 - val_loss: 0.3501 - val_accuracy: 0.8620\n",
      "Epoch 2/100\n",
      "157/157 - 1s - loss: 0.0603 - accuracy: 0.9907 - val_loss: 0.3364 - val_accuracy: 0.8665\n",
      "Epoch 3/100\n",
      "157/157 - 1s - loss: 0.0298 - accuracy: 0.9968 - val_loss: 0.3266 - val_accuracy: 0.8880\n",
      "Epoch 4/100\n",
      "157/157 - 1s - loss: 0.0244 - accuracy: 0.9962 - val_loss: 0.3244 - val_accuracy: 0.8930\n",
      "Epoch 5/100\n",
      "157/157 - 1s - loss: 0.0149 - accuracy: 0.9982 - val_loss: 0.4084 - val_accuracy: 0.8880\n",
      "Epoch 6/100\n",
      "157/157 - 1s - loss: 0.0068 - accuracy: 0.9995 - val_loss: 0.3649 - val_accuracy: 0.8810\n",
      "Epoch 7/100\n",
      "157/157 - 1s - loss: 0.0056 - accuracy: 0.9997 - val_loss: 0.5500 - val_accuracy: 0.8565\n",
      "Epoch 8/100\n",
      "157/157 - 1s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4304 - val_accuracy: 0.8825\n",
      "Epoch 9/100\n",
      "157/157 - 2s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4124 - val_accuracy: 0.8895\n",
      "Finished training\n",
      "Saved model\n",
      "Siamese EER: 0.098\n",
      "Siamese Accuracy: 0.902\n",
      "SVM Accuracy: 0.875\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2064 - acc: 0.8735\n",
      "ANN Accuracy: 0.8734999895095825\n",
      "KNN Accuracy: 0.843\n",
      "Run #2:\n",
      "Loaded data\n",
      "Built model\n",
      "Start training ...\n",
      "Epoch 1/100\n",
      "157/157 - 3s - loss: 0.1742 - accuracy: 0.9518 - val_loss: 0.4443 - val_accuracy: 0.8320\n",
      "Epoch 2/100\n",
      "157/157 - 1s - loss: 0.0631 - accuracy: 0.9885 - val_loss: 0.6084 - val_accuracy: 0.7575\n",
      "Epoch 3/100\n",
      "157/157 - 1s - loss: 0.0376 - accuracy: 0.9937 - val_loss: 0.4679 - val_accuracy: 0.8340\n",
      "Epoch 4/100\n",
      "157/157 - 1s - loss: 0.0265 - accuracy: 0.9962 - val_loss: 0.5874 - val_accuracy: 0.7990\n",
      "Epoch 5/100\n",
      "157/157 - 1s - loss: 0.0228 - accuracy: 0.9964 - val_loss: 0.4715 - val_accuracy: 0.8285\n",
      "Epoch 6/100\n",
      "157/157 - 1s - loss: 0.0165 - accuracy: 0.9975 - val_loss: 0.6239 - val_accuracy: 0.8070\n",
      "Epoch 7/100\n",
      "157/157 - 1s - loss: 0.0107 - accuracy: 0.9986 - val_loss: 0.6328 - val_accuracy: 0.8070\n",
      "Epoch 8/100\n",
      "157/157 - 1s - loss: 0.0072 - accuracy: 0.9989 - val_loss: 0.6406 - val_accuracy: 0.8130\n",
      "Finished training\n",
      "Saved model\n",
      "Siamese EER: 0.067\n",
      "Siamese Accuracy: 0.933\n",
      "SVM Accuracy: 0.951\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5941 - acc: 0.9270\n",
      "ANN Accuracy: 0.9269999861717224\n",
      "KNN Accuracy: 0.918\n",
      "Run #3:\n",
      "Loaded data\n",
      "Built model\n",
      "Start training ...\n",
      "Epoch 1/100\n",
      "157/157 - 3s - loss: 0.1604 - accuracy: 0.9561 - val_loss: 0.4918 - val_accuracy: 0.7940\n",
      "Epoch 2/100\n",
      "157/157 - 1s - loss: 0.0438 - accuracy: 0.9935 - val_loss: 0.4648 - val_accuracy: 0.8225\n",
      "Epoch 3/100\n",
      "157/157 - 1s - loss: 0.0274 - accuracy: 0.9958 - val_loss: 0.4794 - val_accuracy: 0.8350\n",
      "Epoch 4/100\n",
      "157/157 - 1s - loss: 0.0148 - accuracy: 0.9983 - val_loss: 0.5673 - val_accuracy: 0.8085\n",
      "Epoch 5/100\n",
      "157/157 - 1s - loss: 0.0083 - accuracy: 0.9995 - val_loss: 0.4564 - val_accuracy: 0.8410\n",
      "Epoch 6/100\n",
      "157/157 - 1s - loss: 0.0078 - accuracy: 0.9995 - val_loss: 0.5350 - val_accuracy: 0.8340\n",
      "Epoch 7/100\n",
      "157/157 - 1s - loss: 0.0147 - accuracy: 0.9973 - val_loss: 0.7463 - val_accuracy: 0.7745\n",
      "Epoch 8/100\n",
      "157/157 - 1s - loss: 0.0161 - accuracy: 0.9981 - val_loss: 0.4892 - val_accuracy: 0.8355\n",
      "Epoch 9/100\n",
      "157/157 - 1s - loss: 0.0070 - accuracy: 0.9992 - val_loss: 0.6890 - val_accuracy: 0.7970\n",
      "Epoch 10/100\n",
      "157/157 - 1s - loss: 0.0044 - accuracy: 0.9993 - val_loss: 0.5407 - val_accuracy: 0.8390\n",
      "Finished training\n",
      "Saved model\n",
      "Siamese EER: 0.092\n",
      "Siamese Accuracy: 0.9075\n",
      "SVM Accuracy: 0.8965\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5007 - acc: 0.9145\n",
      "ANN Accuracy: 0.9144999980926514\n",
      "KNN Accuracy: 0.888\n",
      "Run #4:\n",
      "Loaded data\n",
      "Built model\n",
      "Start training ...\n",
      "Epoch 1/100\n",
      "157/157 - 3s - loss: 0.1918 - accuracy: 0.9469 - val_loss: 0.7962 - val_accuracy: 0.6995\n",
      "Epoch 2/100\n",
      "157/157 - 1s - loss: 0.0530 - accuracy: 0.9931 - val_loss: 1.0238 - val_accuracy: 0.6995\n",
      "Epoch 3/100\n",
      "157/157 - 1s - loss: 0.0232 - accuracy: 0.9981 - val_loss: 1.0782 - val_accuracy: 0.6970\n",
      "Epoch 4/100\n",
      "157/157 - 2s - loss: 0.0112 - accuracy: 0.9994 - val_loss: 1.3134 - val_accuracy: 0.6995\n",
      "Epoch 5/100\n",
      "157/157 - 2s - loss: 0.0060 - accuracy: 0.9999 - val_loss: 1.4083 - val_accuracy: 0.6995\n",
      "Epoch 6/100\n",
      "157/157 - 2s - loss: 0.0053 - accuracy: 0.9997 - val_loss: 1.6073 - val_accuracy: 0.6975\n",
      "Finished training\n",
      "Saved model\n",
      "Siamese EER: 0.203\n",
      "Siamese Accuracy: 0.797\n",
      "SVM Accuracy: 0.886\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1067 - acc: 0.8575\n",
      "ANN Accuracy: 0.8575000166893005\n",
      "KNN Accuracy: 0.8525\n",
      "Run #5:\n",
      "Loaded data\n",
      "Built model\n",
      "Start training ...\n",
      "Epoch 1/100\n",
      "157/157 - 3s - loss: 0.1981 - accuracy: 0.9421 - val_loss: 0.5918 - val_accuracy: 0.7275\n",
      "Epoch 2/100\n",
      "157/157 - 1s - loss: 0.0618 - accuracy: 0.9903 - val_loss: 0.9086 - val_accuracy: 0.6770\n",
      "Epoch 3/100\n",
      "157/157 - 1s - loss: 0.0304 - accuracy: 0.9968 - val_loss: 1.2056 - val_accuracy: 0.6445\n",
      "Epoch 4/100\n",
      "157/157 - 1s - loss: 0.0229 - accuracy: 0.9976 - val_loss: 0.9577 - val_accuracy: 0.7055\n",
      "Epoch 5/100\n",
      "157/157 - 1s - loss: 0.0136 - accuracy: 0.9986 - val_loss: 0.8878 - val_accuracy: 0.7270\n",
      "Epoch 6/100\n",
      "157/157 - 2s - loss: 0.0102 - accuracy: 0.9992 - val_loss: 1.3704 - val_accuracy: 0.6725\n",
      "Finished training\n",
      "Saved model\n",
      "Siamese EER: 0.226\n",
      "Siamese Accuracy: 0.774\n",
      "SVM Accuracy: 0.8855\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.2770 - acc: 0.8340\n",
      "ANN Accuracy: 0.8339999914169312\n",
      "KNN Accuracy: 0.854\n",
      "Run #6:\n",
      "Loaded data\n",
      "Built model\n",
      "Start training ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "157/157 - 3s - loss: 0.2127 - accuracy: 0.9395 - val_loss: 0.3207 - val_accuracy: 0.9290\n",
      "Epoch 2/100\n",
      "157/157 - 1s - loss: 0.0598 - accuracy: 0.9915 - val_loss: 0.3268 - val_accuracy: 0.9330\n",
      "Epoch 3/100\n",
      "157/157 - 1s - loss: 0.0281 - accuracy: 0.9972 - val_loss: 0.3839 - val_accuracy: 0.9285\n",
      "Epoch 4/100\n",
      "157/157 - 2s - loss: 0.0164 - accuracy: 0.9982 - val_loss: 0.3186 - val_accuracy: 0.9425\n",
      "Epoch 5/100\n",
      "157/157 - 1s - loss: 0.0106 - accuracy: 0.9990 - val_loss: 0.3409 - val_accuracy: 0.9370\n",
      "Epoch 6/100\n",
      "157/157 - 1s - loss: 0.0059 - accuracy: 0.9999 - val_loss: 0.3814 - val_accuracy: 0.9275\n",
      "Epoch 7/100\n",
      "157/157 - 2s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.3636 - val_accuracy: 0.9345\n",
      "Epoch 8/100\n",
      "157/157 - 2s - loss: 0.0038 - accuracy: 0.9998 - val_loss: 0.4028 - val_accuracy: 0.9270\n",
      "Epoch 9/100\n",
      "157/157 - 2s - loss: 0.0230 - accuracy: 0.9965 - val_loss: 0.3192 - val_accuracy: 0.9280\n",
      "Finished training\n",
      "Saved model\n",
      "Siamese EER: 0.099\n",
      "Siamese Accuracy: 0.901\n",
      "SVM Accuracy: 0.9135\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3023 - acc: 0.8690\n",
      "ANN Accuracy: 0.8690000176429749\n",
      "KNN Accuracy: 0.86\n",
      "Run #7:\n",
      "Loaded data\n",
      "Built model\n",
      "Start training ...\n",
      "Epoch 1/100\n",
      "157/157 - 3s - loss: 0.1973 - accuracy: 0.9444 - val_loss: 0.3972 - val_accuracy: 0.8160\n",
      "Epoch 2/100\n",
      "157/157 - 1s - loss: 0.0598 - accuracy: 0.9913 - val_loss: 0.5136 - val_accuracy: 0.8065\n",
      "Epoch 3/100\n",
      "157/157 - 1s - loss: 0.0308 - accuracy: 0.9968 - val_loss: 0.5400 - val_accuracy: 0.8080\n",
      "Epoch 4/100\n",
      "157/157 - 1s - loss: 0.0184 - accuracy: 0.9985 - val_loss: 0.5786 - val_accuracy: 0.8000\n",
      "Epoch 5/100\n",
      "157/157 - 1s - loss: 0.0097 - accuracy: 0.9991 - val_loss: 0.6190 - val_accuracy: 0.8050\n",
      "Epoch 6/100\n",
      "157/157 - 1s - loss: 0.0063 - accuracy: 0.9996 - val_loss: 0.8549 - val_accuracy: 0.7715\n",
      "Finished training\n",
      "Saved model\n",
      "Siamese EER: 0.209\n",
      "Siamese Accuracy: 0.791\n",
      "SVM Accuracy: 0.9315\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5953 - acc: 0.8670\n",
      "ANN Accuracy: 0.8669999837875366\n",
      "KNN Accuracy: 0.8625\n",
      "Run #8:\n",
      "Loaded data\n",
      "Built model\n",
      "Start training ...\n",
      "Epoch 1/100\n",
      "157/157 - 3s - loss: 0.2020 - accuracy: 0.9387 - val_loss: 0.2285 - val_accuracy: 0.9300\n",
      "Epoch 2/100\n",
      "157/157 - 1s - loss: 0.0819 - accuracy: 0.9839 - val_loss: 0.1777 - val_accuracy: 0.9385\n",
      "Epoch 3/100\n",
      "157/157 - 2s - loss: 0.0428 - accuracy: 0.9923 - val_loss: 0.1430 - val_accuracy: 0.9495\n",
      "Epoch 4/100\n",
      "157/157 - 2s - loss: 0.0277 - accuracy: 0.9963 - val_loss: 0.1630 - val_accuracy: 0.9445\n",
      "Epoch 5/100\n",
      "157/157 - 2s - loss: 0.0197 - accuracy: 0.9976 - val_loss: 0.1438 - val_accuracy: 0.9490\n",
      "Epoch 6/100\n",
      "157/157 - 2s - loss: 0.0172 - accuracy: 0.9976 - val_loss: 0.1690 - val_accuracy: 0.9425\n",
      "Epoch 7/100\n",
      "157/157 - 2s - loss: 0.0136 - accuracy: 0.9978 - val_loss: 0.1677 - val_accuracy: 0.9405\n",
      "Epoch 8/100\n",
      "157/157 - 2s - loss: 0.0082 - accuracy: 0.9987 - val_loss: 0.1465 - val_accuracy: 0.9510\n",
      "Epoch 9/100\n",
      "157/157 - 2s - loss: 0.0096 - accuracy: 0.9986 - val_loss: 0.2302 - val_accuracy: 0.9195\n",
      "Epoch 10/100\n",
      "157/157 - 1s - loss: 0.0085 - accuracy: 0.9988 - val_loss: 0.1472 - val_accuracy: 0.9505\n",
      "Epoch 11/100\n",
      "157/157 - 1s - loss: 0.0102 - accuracy: 0.9984 - val_loss: 0.1685 - val_accuracy: 0.9425\n",
      "Epoch 12/100\n",
      "157/157 - 1s - loss: 0.0056 - accuracy: 0.9992 - val_loss: 0.1566 - val_accuracy: 0.9515\n",
      "Epoch 13/100\n",
      "157/157 - 1s - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.1693 - val_accuracy: 0.9480\n",
      "Epoch 14/100\n",
      "157/157 - 2s - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.2118 - val_accuracy: 0.9355\n",
      "Epoch 15/100\n",
      "157/157 - 2s - loss: 0.0068 - accuracy: 0.9991 - val_loss: 0.1535 - val_accuracy: 0.9500\n",
      "Epoch 16/100\n",
      "157/157 - 2s - loss: 0.0100 - accuracy: 0.9984 - val_loss: 0.1506 - val_accuracy: 0.9540\n",
      "Epoch 17/100\n",
      "157/157 - 2s - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.1728 - val_accuracy: 0.9415\n",
      "Epoch 18/100\n",
      "157/157 - 2s - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.1408 - val_accuracy: 0.9550\n",
      "Epoch 19/100\n",
      "157/157 - 2s - loss: 0.0029 - accuracy: 0.9998 - val_loss: 0.1407 - val_accuracy: 0.9570\n",
      "Epoch 20/100\n",
      "157/157 - 2s - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.1926 - val_accuracy: 0.9450\n",
      "Epoch 21/100\n",
      "157/157 - 2s - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.1922 - val_accuracy: 0.9510\n",
      "Epoch 22/100\n",
      "157/157 - 1s - loss: 0.0084 - accuracy: 0.9980 - val_loss: 0.1583 - val_accuracy: 0.9525\n",
      "Epoch 23/100\n",
      "157/157 - 2s - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.0750 - val_accuracy: 0.9740\n",
      "Epoch 24/100\n",
      "157/157 - 1s - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.1839 - val_accuracy: 0.9415\n",
      "Epoch 25/100\n",
      "157/157 - 2s - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.1689 - val_accuracy: 0.9540\n",
      "Epoch 26/100\n",
      "157/157 - 2s - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.1155 - val_accuracy: 0.9625\n",
      "Epoch 27/100\n",
      "157/157 - 1s - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.2155 - val_accuracy: 0.9410\n",
      "Epoch 28/100\n",
      "157/157 - 2s - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.1864 - val_accuracy: 0.9420\n",
      "Finished training\n",
      "Saved model\n",
      "Siamese EER: 0.158\n",
      "Siamese Accuracy: 0.842\n",
      "SVM Accuracy: 0.9225\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5345 - acc: 0.8425\n",
      "ANN Accuracy: 0.8424999713897705\n",
      "KNN Accuracy: 0.7365\n",
      "Run #9:\n",
      "Loaded data\n",
      "Built model\n",
      "Start training ...\n",
      "Epoch 1/100\n",
      "157/157 - 3s - loss: 0.2142 - accuracy: 0.9346 - val_loss: 0.2440 - val_accuracy: 0.9115\n",
      "Epoch 2/100\n",
      "157/157 - 1s - loss: 0.0619 - accuracy: 0.9899 - val_loss: 0.2349 - val_accuracy: 0.9155\n",
      "Epoch 3/100\n",
      "157/157 - 1s - loss: 0.0300 - accuracy: 0.9960 - val_loss: 0.2608 - val_accuracy: 0.9165\n",
      "Epoch 4/100\n",
      "157/157 - 1s - loss: 0.0195 - accuracy: 0.9977 - val_loss: 0.2680 - val_accuracy: 0.9125\n",
      "Epoch 5/100\n",
      "157/157 - 1s - loss: 0.0125 - accuracy: 0.9990 - val_loss: 0.3031 - val_accuracy: 0.9255\n",
      "Epoch 6/100\n",
      "157/157 - 1s - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.3211 - val_accuracy: 0.9160\n",
      "Epoch 7/100\n",
      "157/157 - 1s - loss: 0.0043 - accuracy: 0.9996 - val_loss: 0.2721 - val_accuracy: 0.9180\n",
      "Epoch 8/100\n",
      "157/157 - 1s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2835 - val_accuracy: 0.9260\n",
      "Epoch 9/100\n",
      "157/157 - 2s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3204 - val_accuracy: 0.9230\n",
      "Epoch 10/100\n",
      "157/157 - 2s - loss: 0.0136 - accuracy: 0.9977 - val_loss: 0.3219 - val_accuracy: 0.8840\n",
      "Epoch 11/100\n",
      "157/157 - 1s - loss: 0.0135 - accuracy: 0.9980 - val_loss: 0.2839 - val_accuracy: 0.9270\n",
      "Epoch 12/100\n",
      "157/157 - 1s - loss: 0.0090 - accuracy: 0.9988 - val_loss: 0.2891 - val_accuracy: 0.9275\n",
      "Epoch 13/100\n",
      "157/157 - 1s - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.2849 - val_accuracy: 0.9255\n",
      "Epoch 14/100\n",
      "157/157 - 1s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3140 - val_accuracy: 0.9270\n",
      "Epoch 15/100\n",
      "157/157 - 2s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3406 - val_accuracy: 0.9255\n",
      "Epoch 16/100\n",
      "157/157 - 2s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3227 - val_accuracy: 0.9310\n",
      "Epoch 17/100\n",
      "157/157 - 1s - loss: 0.0063 - accuracy: 0.9989 - val_loss: 0.2674 - val_accuracy: 0.9245\n",
      "Epoch 18/100\n",
      "157/157 - 1s - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.4237 - val_accuracy: 0.9085\n",
      "Epoch 19/100\n",
      "157/157 - 1s - loss: 0.0140 - accuracy: 0.9966 - val_loss: 0.2785 - val_accuracy: 0.9235\n",
      "Epoch 20/100\n",
      "157/157 - 1s - loss: 0.0029 - accuracy: 0.9998 - val_loss: 0.3476 - val_accuracy: 0.9105\n",
      "Epoch 21/100\n",
      "157/157 - 1s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3336 - val_accuracy: 0.9265\n",
      "Finished training\n",
      "Saved model\n",
      "Siamese EER: 0.156\n",
      "Siamese Accuracy: 0.844\n",
      "SVM Accuracy: 0.9235\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 2.2159 - acc: 0.8135\n",
      "ANN Accuracy: 0.8134999871253967\n",
      "KNN Accuracy: 0.8415\n",
      "[0.867  0.902  0.933  0.9075 0.797  0.774  0.901  0.791  0.842  0.844 ]\n",
      "siamese accuracy: 0.85585 +/- 0.05254809701597194\n",
      "[0.9255 0.875  0.951  0.8965 0.886  0.8855 0.9135 0.9315 0.9225 0.9235]\n",
      "svm accuracy: 0.91105 +/- 0.023036330002845502\n",
      "[0.8915 0.8735 0.927  0.9145 0.8575 0.834  0.869  0.867  0.8425 0.8135]\n",
      "ann accuracy: 0.8689999938011169 +/- 0.03332341696691933\n",
      "[0.929  0.843  0.918  0.888  0.8525 0.854  0.86   0.8625 0.7365 0.8415]\n",
      "knn accuracy: 0.8585 +/- 0.04986832662121319\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hiy6B7cuTFxm",
    "outputId": "0d3b8a68-833f-49db-8694-01d1d4aa6146"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "adam = Adam(learning_rate=0.001)\n",
    "cnn = build_model5(left_shape, bn=1, reg=0)\n",
    "siamese = models.build_siamese(left_shape, cnn, 0.1)\n",
    "siamese.compile(loss='binary_crossentropy', optimizer=adam, metrics=[BinaryAccuracy(name='accuracy')])\n",
    "siamese.load_weights(os.path.join(results_path, 'osaka', 'model_r{}_weights.h5'.format(0)))"
   ],
   "outputs": [],
   "metadata": {
    "id": "WDLnLi2nhjDC"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Siamese network direct test accuracy:')\n",
    "siamese.evaluate([l_input_test, r_input_test], b_labels_test)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "68zo_lIziFii",
    "outputId": "b6a9d60a-7cf9-41bd-b676-6b2cfdc0991e"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "print('Siamese network direct test accuracy:')\n",
    "siamese.evaluate([l_input_test, r_input_test], b_labels_test)\n",
    "\n",
    "print('==========SVM==========')\n",
    "classifier = SVC(kernel='poly', degree=10, C=100)\n",
    "feature_exctractor = Model(inputs=[siamese.get_layer('left_input').input,siamese.get_layer('right_input').input], outputs=siamese.get_layer('lambda').output)\n",
    "d_vect = feature_exctractor.predict([l_input, r_input])\n",
    "d_vect_test = feature_exctractor.predict([l_input_test, r_input_test])\n",
    "print(d_vect.shape)\n",
    "\n",
    "classifier.fit(d_vect, b_labels)\n",
    "svc_score = classifier.score(d_vect_test, b_labels_test)\n",
    "print('SVC mean test accuracy:', svc_score*100)\n",
    "\n",
    "pca = PCA(2)\n",
    "colors = ['#800000',\n",
    "          '#bfef45']\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(121)\n",
    "plt.title('Ground Truth')\n",
    "d_vect_test_2d = pca.fit_transform(d_vect_test)\n",
    "plt.scatter(d_vect_test_2d[:, 0], d_vect_test_2d[:, 1], c=[colors[i] for i in b_labels_test], alpha=0.2)\n",
    "plt.subplot(122)\n",
    "plt.title('Prediction')\n",
    "d_vect_test_2d = pca.fit_transform(d_vect_test)\n",
    "plt.scatter(d_vect_test_2d[:, 0], d_vect_test_2d[:, 1], c=[colors[i] for i in classifier.predict(d_vect_test)], alpha=0.2)\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "id": "iK0wUaUgTFxn"
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "osaka_cls_retrain.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}