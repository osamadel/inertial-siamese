{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvAor71-TFxU"
   },
   "source": [
    "# IJCNN Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-DBFcSs6TFxe"
   },
   "source": [
    "Roughly speaking, I will try to use the models trained on the datasets, then remove the FC layer and add other classifiers. Then I will report the result of the other classifiers on the final performance using either EER or accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cOPS399rTFxe"
   },
   "outputs": [],
   "source": [
    "data_path = '../data/osaka'\n",
    "results_path = '../results/'\n",
    "\n",
    "# data_path = '/content/drive/MyDrive/IJCNN/data/osaka'\n",
    "# results_path = '/content/drive/MyDrive/IJCNN/results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OI-lQFRRKEAY",
    "outputId": "7e85a733-61b5-4742-a5c2-2ed5b6502d45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jArT8WzDKPH2",
    "outputId": "e463a28e-25ed-4c96-870b-9cfec0a36b87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyze.py  datasets.py  drive\tmodels.py  sample_data\tsrc\n"
     ]
    }
   ],
   "source": [
    "!cp -r \"/content/drive/MyDrive/IJCNN/src\" /content/\n",
    "!mv src/datasets.py datasets.py\n",
    "!mv src/models.py models.py\n",
    "!mv src/analyze.py analyze.py\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "k0TFGFVAKTNo"
   },
   "outputs": [],
   "source": [
    "import datasets, models, analyze\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import activations\n",
    "# from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "# import nevergrad as ng\n",
    "import os\n",
    "np.set_printoptions(precision=4)\n",
    "gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Qwqf4RGPJ08n"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jvrnb1vgKVPf"
   },
   "outputs": [],
   "source": [
    "def prepare_data(train_sps, val_sps, test_sps, max_cls, split, data, labels, indices_list, run_n):\n",
    "    train_split = int(split[0] * max_cls)\n",
    "    val_split = int(split[2] * max_cls)\n",
    "\n",
    "    rand_indices = np.random.choice(range(max_cls), size=max_cls, replace=False)\n",
    "    indices_list.append(rand_indices)\n",
    "    print('Run #%d:'%run_n)\n",
    "    \n",
    "    all_data_rand, all_labels_rand = [data[x] for x in rand_indices], [labels[x] for x in rand_indices]\n",
    "    b_data, b_labels = datasets.generate_batch(train_sps, all_data_rand[:train_split], all_labels_rand[:train_split])\n",
    "    \n",
    "    val_data, val_labels = datasets.generate_batch(val_sps, all_data_rand[train_split:train_split+val_split], all_labels_rand[train_split:train_split+val_split])\n",
    "    ridx = np.random.choice(range(b_data[0].shape[0]), size=b_data[0].shape[0], replace=False)\n",
    "    \n",
    "    b_data_test, b_labels_test = datasets.generate_batch(test_sps, all_data_rand[train_split+val_split:], all_labels_rand[train_split+val_split:])\n",
    "\n",
    "    l_input = b_data[0][ridx]\n",
    "    r_input = b_data[1][ridx]\n",
    "    b_labels = b_labels[ridx]\n",
    "\n",
    "    # print(l_input[0].shape)\n",
    "\n",
    "    l_input_val = val_data[0]\n",
    "    r_input_val = val_data[1]\n",
    "\n",
    "    l_input_test = b_data_test[0]\n",
    "    r_input_test = b_data_test[1]\n",
    "    return l_input, r_input, b_labels, l_input_val, r_input_val, val_labels, l_input_test, r_input_test, b_labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "JYx3YqoxK4PG"
   },
   "outputs": [],
   "source": [
    "def load_dataset(segLen, overlap, acc_only):\n",
    "    data, labels = datasets.load_segment_osaka(data_path, \n",
    "                                            [0,744], \n",
    "                                            sample_rate=100,\n",
    "                                            acc_only=acc_only,\n",
    "                                            segment_time=segLen, \n",
    "                                            overlapped=overlap, \n",
    "                                            overlap=overlap, \n",
    "                                            downsample=True)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-h4dUZV8WXlb"
   },
   "outputs": [],
   "source": [
    "def build_model1(input_shape, bn, reg):\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Conv1D, \\\n",
    "                                        MaxPooling1D, \\\n",
    "                                        AveragePooling1D, \\\n",
    "                                        Dense, Flatten, Dropout, \\\n",
    "                                        BatchNormalization, \\\n",
    "                                        GlobalMaxPooling1D, \\\n",
    "                                        GlobalAveragePooling1D, \\\n",
    "                                        Activation\n",
    "    from tensorflow.keras import activations\n",
    "    import tensorflow.keras.regularizers as regularizers\n",
    "\n",
    "    model = Sequential()\n",
    "    if reg:\n",
    "        model.add(Conv1D(16, 3, strides=1, input_shape=input_shape, \n",
    "                        kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                        bias_regularizer=regularizers.l2(1e-4)))\n",
    "    else:\n",
    "        model.add(Conv1D(16, 3, strides=1, input_shape=input_shape))\n",
    "    if bn:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Activation(activations.relu))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    if reg:\n",
    "        model.add(Conv1D(64, 5, strides=2, \n",
    "                        kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                        bias_regularizer=regularizers.l2(1e-4)))\n",
    "    else:\n",
    "        model.add(Conv1D(64, 5, strides=2))\n",
    "    if bn:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Activation(activations.relu))\n",
    "    model.add(AveragePooling1D(pool_size=2))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Auc0ROjJXJ4a"
   },
   "outputs": [],
   "source": [
    "# def build_model2(input_shape, bn, reg):\n",
    "#     from tensorflow.keras.models import Sequential\n",
    "#     from tensorflow.keras.layers import Conv1D, \\\n",
    "#                                         MaxPooling1D, \\\n",
    "#                                         AveragePooling1D, \\\n",
    "#                                         Dense, Flatten, Dropout, \\\n",
    "#                                         BatchNormalization, \\\n",
    "#                                         GlobalMaxPooling1D, \\\n",
    "#                                         GlobalAveragePooling1D, \\\n",
    "#                                         Activation\n",
    "#     from tensorflow.keras import activations\n",
    "#     import tensorflow.keras.regularizers as regularizers\n",
    "\n",
    "#     model = Sequential()\n",
    "#     if reg:\n",
    "#         model.add(Conv1D(16, 3, strides=1, activation='tanh', input_shape=input_shape, kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),bias_regularizer=regularizers.l2(1e-4)))\n",
    "#         model.add(Conv1D(32, 3, strides=2, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),bias_regularizer=regularizers.l2(1e-4)))\n",
    "#     else:\n",
    "#         model.add(Conv1D(16, 3, strides=1, activation='tanh', input_shape=input_shape))\n",
    "#         model.add(Conv1D(32, 3, strides=2, activation='relu'))\n",
    "    \n",
    "#     if bn:\n",
    "#         model.add(BatchNormalization())\n",
    "\n",
    "#     model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "#     if reg:\n",
    "#         model.add(Conv1D(64, 5, strides=2, activation='tanh', kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),bias_regularizer=regularizers.l2(1e-4)))\n",
    "#         model.add(Conv1D(128, 5, strides=3, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),bias_regularizer=regularizers.l2(1e-4)))\n",
    "#     else:\n",
    "#         model.add(Conv1D(64, 5, strides=2, activation='tanh'))\n",
    "#         model.add(Conv1D(128, 5, strides=3, activation='relu'))\n",
    "    \n",
    "#     if bn:\n",
    "#         model.add(BatchNormalization())\n",
    "\n",
    "#     model.add(GlobalMaxPooling1D())\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1S9BaZbCZajy"
   },
   "outputs": [],
   "source": [
    "# def build_model3(input_shape, bn, reg):\n",
    "#     from tensorflow.keras.models import Sequential\n",
    "#     from tensorflow.keras.layers import Conv1D, \\\n",
    "#                                         MaxPooling1D, \\\n",
    "#                                         AveragePooling1D, \\\n",
    "#                                         Dense, Flatten, Dropout, \\\n",
    "#                                         BatchNormalization, \\\n",
    "#                                         GlobalMaxPooling1D, \\\n",
    "#                                         GlobalAveragePooling1D, \\\n",
    "#                                         Activation\n",
    "#     from tensorflow.keras import activations\n",
    "#     import tensorflow.keras.regularizers as regularizers\n",
    "\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv1D(64, 5, strides=3, padding='valid', activation='relu', input_shape=input_shape))\n",
    "#     if bn: model.add(BatchNormalization())\n",
    "#     model.add(Conv1D(128, 3, strides=2, padding='valid', activation='relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "#     model.add(Conv1D(128, 2, strides=1, padding='valid', activation='tanh'))\n",
    "#     model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "#     model.add(GlobalMaxPooling1D())\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "q7x9rfwDIqx-"
   },
   "outputs": [],
   "source": [
    "def build_model4(input_shape, bn, reg):\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Conv1D, \\\n",
    "                                        MaxPooling1D, \\\n",
    "                                        AveragePooling1D, \\\n",
    "                                        Dense, Flatten, Dropout, \\\n",
    "                                        BatchNormalization, \\\n",
    "                                        GlobalMaxPooling1D, \\\n",
    "                                        GlobalAveragePooling1D, \\\n",
    "                                        Activation\n",
    "    from tensorflow.keras import activations\n",
    "    import tensorflow.keras.regularizers as regularizers\n",
    "\n",
    "    model = Sequential()\n",
    "    if reg:\n",
    "        model.add(Conv1D(32, 3, strides=1, input_shape=input_shape, \n",
    "                        kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                        bias_regularizer=regularizers.l2(1e-4)))\n",
    "    else:\n",
    "        model.add(Conv1D(32, 3, strides=1, input_shape=input_shape))\n",
    "    if bn:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Activation(activations.relu))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    if reg:\n",
    "        model.add(Conv1D(128, 5, strides=2, \n",
    "                        kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                        bias_regularizer=regularizers.l2(1e-4)))\n",
    "    else:\n",
    "        model.add(Conv1D(128, 5, strides=2))\n",
    "    if bn:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Activation(activations.relu))\n",
    "    model.add(AveragePooling1D(pool_size=2))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "F28ig3xVIzuJ"
   },
   "outputs": [],
   "source": [
    "def build_model5(input_shape, bn, reg):\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Conv1D, \\\n",
    "                                        MaxPooling1D, \\\n",
    "                                        AveragePooling1D, \\\n",
    "                                        Dense, Flatten, Dropout, \\\n",
    "                                        BatchNormalization, \\\n",
    "                                        GlobalMaxPooling1D, \\\n",
    "                                        GlobalAveragePooling1D, \\\n",
    "                                        Activation\n",
    "    from tensorflow.keras import activations\n",
    "    import tensorflow.keras.regularizers as regularizers\n",
    "\n",
    "    model = Sequential()\n",
    "    if reg:\n",
    "        model.add(Conv1D(64, 3, strides=1, input_shape=input_shape, \n",
    "                        kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                        bias_regularizer=regularizers.l2(1e-4)))\n",
    "    else:\n",
    "        model.add(Conv1D(64, 3, strides=1, input_shape=input_shape))\n",
    "    if bn:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Activation(activations.relu))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    if reg:\n",
    "        model.add(Conv1D(256, 5, strides=2, \n",
    "                        kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                        bias_regularizer=regularizers.l2(1e-4)))\n",
    "    else:\n",
    "        model.add(Conv1D(256, 5, strides=2))\n",
    "    if bn:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Activation(activations.relu))\n",
    "    model.add(AveragePooling1D(pool_size=2))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "DFUOb5_GUo-e"
   },
   "outputs": [],
   "source": [
    "acc_only_list    = [False, True]\n",
    "segLen_list      = [1, 2]\n",
    "overlap_list     = [0, 0.25, 0.5, 0.75]\n",
    "# models_list      = [build_model1, build_model2, build_model3]\n",
    "models_list      = [build_model5]\n",
    "# bn_list          = [True, False]\n",
    "bn_list          = [True]\n",
    "# reg_list         = [True, False]\n",
    "reg_list         = [False]\n",
    "\n",
    "# Configurations\n",
    "train_sps       = 50\n",
    "val_sps         = 20\n",
    "test_sps        = 20\n",
    "max_cls         = 744\n",
    "split           = [0.8, 0.1, 0.1]\n",
    "output_dropout  = 0.1\n",
    "runs            = 10\n",
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "CxkqRdMpDOip"
   },
   "outputs": [],
   "source": [
    "def getSiameseAcc(siamese, test_set, EER_th):\n",
    "    # l_input_test, r_input_test = test_set[0]\n",
    "    b_labels_test = test_set[1]\n",
    "    # print('EER threshold:', EER_th)\n",
    "    # print(np.uint8(np.squeeze(siamese.predict(test_set[0])) >= EER_th))\n",
    "    # print(b_labels_test)\n",
    "    return np.mean(np.uint8(np.squeeze(siamese.predict(test_set[0])) >= EER_th) == b_labels_test)\n",
    "\n",
    "def trainSVM(siamese, training_set, test_set):\n",
    "    l_input, r_input = training_set[0]\n",
    "    b_labels = training_set[1]\n",
    "    l_input_test, r_input_test = test_set[0]\n",
    "    b_labels_test = test_set[1]\n",
    "\n",
    "    # classifier = SVC(kernel='poly', degree=10, C=100)\n",
    "    classifier = SVC(kernel='poly', degree=5, C=10)\n",
    "    feature_exctractor = Model(inputs=[siamese.get_layer('left_input').input,siamese.get_layer('right_input').input], outputs=siamese.get_layer('lambda').output)\n",
    "    d_vect = feature_exctractor.predict([l_input, r_input])\n",
    "    d_vect_test = feature_exctractor.predict([l_input_test, r_input_test])\n",
    "    \n",
    "    # print(d_vect.shape)\n",
    "\n",
    "    classifier.fit(d_vect, b_labels)\n",
    "    svc_score = classifier.score(d_vect_test, b_labels_test)\n",
    "    # print('SVC mean test accuracy:', svc_score*100)\n",
    "    return svc_score\n",
    "\n",
    "def trainKNN(siamese, training_set, test_set):\n",
    "    l_input, r_input = training_set[0]\n",
    "    b_labels = training_set[1]\n",
    "    l_input_test, r_input_test = test_set[0]\n",
    "    b_labels_test = test_set[1]\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    feature_exctractor = Model(inputs=[siamese.get_layer('left_input').input,siamese.get_layer('right_input').input], outputs=siamese.get_layer('lambda').output)\n",
    "    d_vect = feature_exctractor.predict([l_input, r_input])\n",
    "    d_vect_test = feature_exctractor.predict([l_input_test, r_input_test])\n",
    "\n",
    "    knn.fit(d_vect, b_labels)\n",
    "    test_predictions = knn.predict(d_vect_test)\n",
    "    knn_score = knn.score(d_vect_test, b_labels_test)\n",
    "    # print('KNN mean test accuracy:', knn_score*100)\n",
    "    return knn_score\n",
    "\n",
    "def trainANN(siamese, training_set, test_set):\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "    l_input, r_input = training_set[0]\n",
    "    b_labels = training_set[1]\n",
    "    l_input_test, r_input_test = test_set[0]\n",
    "    b_labels_test = test_set[1]\n",
    "\n",
    "    feature_exctractor = Model(inputs=[siamese.get_layer('left_input').input,siamese.get_layer('right_input').input], outputs=siamese.get_layer('lambda').output)\n",
    "    d_vect = feature_exctractor.predict([l_input, r_input])\n",
    "    d_vect_test = feature_exctractor.predict([l_input_test, r_input_test])\n",
    "\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(8, activation='relu', input_shape=(256,)))\n",
    "    classifier.add(Dropout(0.3))\n",
    "    classifier.add(Dense(8, activation='relu'))\n",
    "    classifier.add(Dropout(0.3))\n",
    "    classifier.add(Dense(1, activation='sigmoid'))\n",
    "    classifier.compile(loss='binary_crossentropy', metrics=['acc'], optimizer='adam')\n",
    "\n",
    "    classifier.fit(d_vect, b_labels, verbose=0, epochs=20, batch_size=128)\n",
    "    # test_predictions = np.uint8(np.squeeze(classifier.predict(d_vect_test) >= 0.5))\n",
    "    # print(test_predictions[:10])\n",
    "    ann_score = classifier.evaluate(d_vect_test, b_labels_test)[1]\n",
    "    # print('ANN mean test accuracy:', ann_score*100)\n",
    "    return ann_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "N-z-EqS3TFxl"
   },
   "outputs": [],
   "source": [
    "def one_run(train_sps, val_sps, test_sps, max_cls, split, data, labels, lst, run_n):\n",
    "    accuracies = {}\n",
    "    l_input, r_input, b_labels \\\n",
    "        , l_input_val, r_input_val, val_labels \\\n",
    "            , l_input_test, r_input_test, b_labels_test = prepare_data( train_sps,\n",
    "                                                                        val_sps,\n",
    "                                                                        test_sps,\n",
    "                                                                        max_cls,\n",
    "                                                                        split,\n",
    "                                                                        data,\n",
    "                                                                        labels,\n",
    "                                                                        [],\n",
    "                                                                        run_n)\n",
    "    print('Loaded data')\n",
    "    adam = Adam(learning_rate=0.001)\n",
    "    earlystop = EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "    \n",
    "    cnn = build_model5(l_input[0].shape, bn=1, reg=0)\n",
    "    siamese = models.build_siamese(l_input[0].shape, cnn, output_dropout)\n",
    "    siamese.compile(loss='binary_crossentropy', optimizer=adam, metrics=[BinaryAccuracy(name='accuracy')])\n",
    "    print('Built model')\n",
    "    if run_n == 0: \n",
    "        cnn.summary()\n",
    "    print('Start training ...')\n",
    "    hist = siamese.fit([l_input, r_input], \n",
    "                        b_labels, \n",
    "                        shuffle=True,\n",
    "                        batch_size=64,\n",
    "                        epochs=100,\n",
    "                        callbacks=[earlystop],\n",
    "                        validation_data=([l_input_val, r_input_val], val_labels),\n",
    "                        verbose=2\n",
    "                        )\n",
    "    print('Finished training')\n",
    "    siamese.save_weights(os.path.join(results_path, 'osaka', 'model_r{}_weights.h5'.format(run_n)))\n",
    "    print('Saved model')\n",
    "    FRR, FAR, EER, EER_th = analyze.ROC(siamese, [l_input_test, r_input_test], b_labels_test)\n",
    "    print('Siamese EER:', EER)\n",
    "    accuracies['siamese'] = getSiameseAcc(siamese, ([l_input_test, r_input_test], b_labels_test), EER_th)\n",
    "    print('Siamese Accuracy:', accuracies['siamese'])\n",
    "    accuracies['svm'] = trainSVM(siamese, ([l_input, r_input], b_labels), ([l_input_test, r_input_test], b_labels_test))\n",
    "    print('SVM Accuracy:', accuracies['svm'])\n",
    "    accuracies['ann'] = trainANN(siamese, ([l_input, r_input], b_labels), ([l_input_test, r_input_test], b_labels_test))\n",
    "    print('ANN Accuracy:', accuracies['ann'])\n",
    "    accuracies['knn'] = trainKNN(siamese, ([l_input, r_input], b_labels), ([l_input_test, r_input_test], b_labels_test))\n",
    "    print('KNN Accuracy:', accuracies['knn'])\n",
    "\n",
    "\n",
    "    return siamese, [FRR, FAR, EER, EER_th], accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7TKW9MyTFxl"
   },
   "source": [
    "### Experiment 1: Train Different Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hiy6B7cuTFxm",
    "outputId": "0d3b8a68-833f-49db-8694-01d1d4aa6146"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run #0:\n",
      "Loaded data\n",
      "Built model\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_4 (Conv1D)            (None, 98, 64)            1216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 98, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 98, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 49, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 23, 256)           82176     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 23, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 23, 256)           0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 11, 256)           0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 256)               0         \n",
      "=================================================================\n",
      "Total params: 84,672\n",
      "Trainable params: 84,032\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Start training ...\n",
      "Epoch 1/100\n",
      "930/930 - 9s - loss: 0.1729 - accuracy: 0.9409 - val_loss: 0.1520 - val_accuracy: 0.9476\n",
      "Epoch 2/100\n",
      "930/930 - 8s - loss: 0.0736 - accuracy: 0.9780 - val_loss: 0.1578 - val_accuracy: 0.9480\n",
      "Epoch 3/100\n",
      "930/930 - 8s - loss: 0.0482 - accuracy: 0.9854 - val_loss: 0.1653 - val_accuracy: 0.9493\n",
      "Epoch 4/100\n",
      "930/930 - 8s - loss: 0.0363 - accuracy: 0.9891 - val_loss: 0.1486 - val_accuracy: 0.9530\n",
      "Epoch 5/100\n",
      "930/930 - 8s - loss: 0.0292 - accuracy: 0.9912 - val_loss: 0.1601 - val_accuracy: 0.9480\n",
      "Epoch 6/100\n",
      "930/930 - 8s - loss: 0.0248 - accuracy: 0.9924 - val_loss: 0.1689 - val_accuracy: 0.9476\n",
      "Epoch 7/100\n",
      "930/930 - 7s - loss: 0.0223 - accuracy: 0.9928 - val_loss: 0.1691 - val_accuracy: 0.9551\n",
      "Epoch 8/100\n",
      "930/930 - 7s - loss: 0.0177 - accuracy: 0.9946 - val_loss: 0.1613 - val_accuracy: 0.9564\n",
      "Epoch 9/100\n",
      "930/930 - 8s - loss: 0.0175 - accuracy: 0.9945 - val_loss: 0.1939 - val_accuracy: 0.9486\n",
      "Epoch 10/100\n",
      "930/930 - 8s - loss: 0.0145 - accuracy: 0.9958 - val_loss: 0.2008 - val_accuracy: 0.9503\n",
      "Epoch 11/100\n",
      "930/930 - 8s - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.1830 - val_accuracy: 0.9503\n",
      "Epoch 12/100\n",
      "930/930 - 8s - loss: 0.0133 - accuracy: 0.9961 - val_loss: 0.1669 - val_accuracy: 0.9524\n",
      "Epoch 13/100\n",
      "930/930 - 7s - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.2007 - val_accuracy: 0.9476\n",
      "Finished training\n",
      "Saved model\n",
      "Siamese EER: 0.032\n",
      "Siamese Accuracy: 0.968\n",
      "SVM Accuracy: 0.9693333333333334\n",
      "94/94 [==============================] - 1s 2ms/step - loss: 0.4027 - acc: 0.9613\n",
      "ANN Accuracy: 0.9613333344459534\n",
      "KNN Accuracy: 0.9673333333333334\n",
      "Run #1:\n",
      "Loaded data\n",
      "Built model\n",
      "Start training ...\n",
      "Epoch 1/100\n",
      "930/930 - 8s - loss: 0.1808 - accuracy: 0.9374 - val_loss: 0.1442 - val_accuracy: 0.9574\n",
      "Epoch 2/100\n",
      "930/930 - 7s - loss: 0.0778 - accuracy: 0.9758 - val_loss: 0.1210 - val_accuracy: 0.9696\n",
      "Epoch 3/100\n",
      "930/930 - 7s - loss: 0.0502 - accuracy: 0.9850 - val_loss: 0.1215 - val_accuracy: 0.9693\n",
      "Epoch 4/100\n",
      "930/930 - 7s - loss: 0.0379 - accuracy: 0.9888 - val_loss: 0.1212 - val_accuracy: 0.9676\n",
      "Epoch 5/100\n",
      "930/930 - 8s - loss: 0.0309 - accuracy: 0.9903 - val_loss: 0.1130 - val_accuracy: 0.9696\n",
      "Epoch 6/100\n",
      "930/930 - 7s - loss: 0.0276 - accuracy: 0.9911 - val_loss: 0.1111 - val_accuracy: 0.9693\n",
      "Epoch 7/100\n",
      "930/930 - 8s - loss: 0.0230 - accuracy: 0.9926 - val_loss: 0.1270 - val_accuracy: 0.9713\n",
      "Epoch 8/100\n",
      "930/930 - 7s - loss: 0.0201 - accuracy: 0.9939 - val_loss: 0.1166 - val_accuracy: 0.9699\n",
      "Epoch 9/100\n",
      "930/930 - 7s - loss: 0.0165 - accuracy: 0.9948 - val_loss: 0.1299 - val_accuracy: 0.9672\n",
      "Epoch 10/100\n",
      "930/930 - 8s - loss: 0.0170 - accuracy: 0.9946 - val_loss: 0.1232 - val_accuracy: 0.9699\n",
      "Epoch 11/100\n",
      "930/930 - 8s - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.1295 - val_accuracy: 0.9720\n",
      "Epoch 12/100\n",
      "930/930 - 6s - loss: 0.0145 - accuracy: 0.9953 - val_loss: 0.1210 - val_accuracy: 0.9730\n",
      "Epoch 13/100\n",
      "930/930 - 7s - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.1348 - val_accuracy: 0.9730\n",
      "Epoch 14/100\n",
      "930/930 - 7s - loss: 0.0116 - accuracy: 0.9964 - val_loss: 0.1310 - val_accuracy: 0.9740\n",
      "Epoch 15/100\n",
      "930/930 - 6s - loss: 0.0102 - accuracy: 0.9971 - val_loss: 0.1464 - val_accuracy: 0.9672\n",
      "Epoch 16/100\n",
      "930/930 - 7s - loss: 0.0109 - accuracy: 0.9967 - val_loss: 0.1214 - val_accuracy: 0.9713\n",
      "Epoch 17/100\n",
      "930/930 - 8s - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.1234 - val_accuracy: 0.9743\n",
      "Epoch 18/100\n",
      "930/930 - 7s - loss: 0.0084 - accuracy: 0.9975 - val_loss: 0.1292 - val_accuracy: 0.9764\n",
      "Epoch 19/100\n",
      "930/930 - 7s - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.1153 - val_accuracy: 0.9753\n",
      "Epoch 20/100\n",
      "930/930 - 8s - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.1230 - val_accuracy: 0.9750\n",
      "Epoch 21/100\n",
      "930/930 - 7s - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.1256 - val_accuracy: 0.9753\n",
      "Epoch 22/100\n",
      "930/930 - 7s - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.1259 - val_accuracy: 0.9730\n",
      "Epoch 23/100\n",
      "930/930 - 7s - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.1340 - val_accuracy: 0.9757\n",
      "Finished training\n",
      "Saved model\n",
      "Siamese EER: 0.021333333333333333\n",
      "Siamese Accuracy: 0.9786666666666667\n",
      "SVM Accuracy: 0.9616666666666667\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.2205 - acc: 0.9680\n",
      "ANN Accuracy: 0.9679999947547913\n",
      "KNN Accuracy: 0.968\n",
      "Run #2:\n",
      "Loaded data\n",
      "Built model\n",
      "Start training ...\n",
      "Epoch 1/100\n",
      "930/930 - 8s - loss: 0.1793 - accuracy: 0.9390 - val_loss: 0.1137 - val_accuracy: 0.9551\n",
      "Epoch 2/100\n",
      "930/930 - 8s - loss: 0.0795 - accuracy: 0.9757 - val_loss: 0.0960 - val_accuracy: 0.9652\n",
      "Epoch 3/100\n",
      "930/930 - 8s - loss: 0.0499 - accuracy: 0.9852 - val_loss: 0.0881 - val_accuracy: 0.9659\n",
      "Epoch 4/100\n",
      "930/930 - 8s - loss: 0.0365 - accuracy: 0.9893 - val_loss: 0.1010 - val_accuracy: 0.9642\n",
      "Epoch 5/100\n",
      "930/930 - 8s - loss: 0.0308 - accuracy: 0.9906 - val_loss: 0.0982 - val_accuracy: 0.9628\n",
      "Epoch 6/100\n",
      "930/930 - 8s - loss: 0.0239 - accuracy: 0.9929 - val_loss: 0.0809 - val_accuracy: 0.9726\n",
      "Epoch 7/100\n",
      "930/930 - 8s - loss: 0.0216 - accuracy: 0.9935 - val_loss: 0.0792 - val_accuracy: 0.9696\n",
      "Epoch 8/100\n",
      "930/930 - 8s - loss: 0.0196 - accuracy: 0.9941 - val_loss: 0.1009 - val_accuracy: 0.9605\n",
      "Epoch 9/100\n",
      "930/930 - 8s - loss: 0.0182 - accuracy: 0.9945 - val_loss: 0.0745 - val_accuracy: 0.9736\n",
      "Epoch 10/100\n",
      "930/930 - 8s - loss: 0.0167 - accuracy: 0.9946 - val_loss: 0.0944 - val_accuracy: 0.9699\n",
      "Epoch 11/100\n",
      "930/930 - 7s - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.1025 - val_accuracy: 0.9639\n",
      "Epoch 12/100\n",
      "930/930 - 8s - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.0972 - val_accuracy: 0.9706\n",
      "Epoch 13/100\n",
      "930/930 - 8s - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.0978 - val_accuracy: 0.9645\n",
      "Epoch 14/100\n",
      "930/930 - 8s - loss: 0.0117 - accuracy: 0.9962 - val_loss: 0.1144 - val_accuracy: 0.9622\n",
      "Finished training\n",
      "Saved model\n",
      "Siamese EER: 0.02666666666666667\n",
      "Siamese Accuracy: 0.9733333333333334\n",
      "SVM Accuracy: 0.962\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4077 - acc: 0.9617\n",
      "ANN Accuracy: 0.9616666436195374\n",
      "KNN Accuracy: 0.9636666666666667\n",
      "Run #3:\n",
      "Loaded data\n",
      "Built model\n",
      "Start training ...\n",
      "Epoch 1/100\n",
      "930/930 - 8s - loss: 0.1833 - accuracy: 0.9364 - val_loss: 0.1158 - val_accuracy: 0.9611\n",
      "Epoch 2/100\n",
      "930/930 - 7s - loss: 0.0785 - accuracy: 0.9755 - val_loss: 0.1124 - val_accuracy: 0.9568\n",
      "Epoch 3/100\n",
      "930/930 - 8s - loss: 0.0502 - accuracy: 0.9849 - val_loss: 0.0868 - val_accuracy: 0.9642\n",
      "Epoch 4/100\n",
      "930/930 - 8s - loss: 0.0391 - accuracy: 0.9884 - val_loss: 0.0909 - val_accuracy: 0.9649\n",
      "Epoch 5/100\n",
      "930/930 - 8s - loss: 0.0306 - accuracy: 0.9911 - val_loss: 0.0979 - val_accuracy: 0.9615\n",
      "Epoch 6/100\n",
      "930/930 - 7s - loss: 0.0258 - accuracy: 0.9924 - val_loss: 0.1246 - val_accuracy: 0.9578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "930/930 - 8s - loss: 0.0212 - accuracy: 0.9936 - val_loss: 0.0931 - val_accuracy: 0.9655\n",
      "Epoch 8/100\n",
      "930/930 - 8s - loss: 0.0212 - accuracy: 0.9933 - val_loss: 0.0826 - val_accuracy: 0.9760\n",
      "Epoch 9/100\n",
      "930/930 - 8s - loss: 0.0162 - accuracy: 0.9948 - val_loss: 0.1070 - val_accuracy: 0.9635\n",
      "Epoch 10/100\n",
      "930/930 - 8s - loss: 0.0156 - accuracy: 0.9952 - val_loss: 0.1085 - val_accuracy: 0.9628\n",
      "Epoch 11/100\n",
      "930/930 - 8s - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.0842 - val_accuracy: 0.9733\n",
      "Epoch 12/100\n",
      "930/930 - 8s - loss: 0.0131 - accuracy: 0.9962 - val_loss: 0.1233 - val_accuracy: 0.9628\n",
      "Epoch 13/100\n",
      "930/930 - 8s - loss: 0.0125 - accuracy: 0.9960 - val_loss: 0.1195 - val_accuracy: 0.9652\n",
      "Finished training\n",
      "Saved model\n",
      "Siamese EER: 0.023333333333333334\n",
      "Siamese Accuracy: 0.9766666666666667\n",
      "SVM Accuracy: 0.9723333333333334\n",
      "94/94 [==============================] - 1s 2ms/step - loss: 0.4699 - acc: 0.9603\n",
      "ANN Accuracy: 0.9603333473205566\n",
      "KNN Accuracy: 0.9753333333333334\n",
      "Run #4:\n",
      "Loaded data\n",
      "Built model\n",
      "Start training ...\n",
      "Epoch 1/100\n",
      "930/930 - 9s - loss: 0.1790 - accuracy: 0.9382 - val_loss: 0.1296 - val_accuracy: 0.9601\n",
      "Epoch 2/100\n",
      "930/930 - 7s - loss: 0.0755 - accuracy: 0.9760 - val_loss: 0.0995 - val_accuracy: 0.9645\n",
      "Epoch 3/100\n",
      "930/930 - 8s - loss: 0.0476 - accuracy: 0.9858 - val_loss: 0.0872 - val_accuracy: 0.9709\n",
      "Epoch 4/100\n",
      "930/930 - 7s - loss: 0.0367 - accuracy: 0.9888 - val_loss: 0.0897 - val_accuracy: 0.9659\n",
      "Epoch 5/100\n",
      "930/930 - 8s - loss: 0.0295 - accuracy: 0.9914 - val_loss: 0.0804 - val_accuracy: 0.9703\n",
      "Epoch 6/100\n",
      "930/930 - 8s - loss: 0.0246 - accuracy: 0.9929 - val_loss: 0.0888 - val_accuracy: 0.9666\n",
      "Epoch 7/100\n",
      "930/930 - 8s - loss: 0.0216 - accuracy: 0.9933 - val_loss: 0.0917 - val_accuracy: 0.9679\n",
      "Epoch 8/100\n",
      "930/930 - 8s - loss: 0.0188 - accuracy: 0.9943 - val_loss: 0.0885 - val_accuracy: 0.9672\n",
      "Finished training\n",
      "Saved model\n",
      "Siamese EER: 0.03333333333333333\n",
      "Siamese Accuracy: 0.9666666666666667\n",
      "SVM Accuracy: 0.973\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3137 - acc: 0.9633\n",
      "ANN Accuracy: 0.9633333086967468\n",
      "KNN Accuracy: 0.9523333333333334\n",
      "Run #5:\n",
      "Loaded data\n",
      "Built model\n",
      "Start training ...\n",
      "Epoch 1/100\n",
      "930/930 - 9s - loss: 0.1843 - accuracy: 0.9375 - val_loss: 0.1205 - val_accuracy: 0.9571\n",
      "Epoch 2/100\n",
      "930/930 - 8s - loss: 0.0752 - accuracy: 0.9772 - val_loss: 0.1046 - val_accuracy: 0.9608\n",
      "Epoch 3/100\n",
      "930/930 - 8s - loss: 0.0489 - accuracy: 0.9851 - val_loss: 0.1094 - val_accuracy: 0.9622\n",
      "Epoch 4/100\n",
      "930/930 - 8s - loss: 0.0376 - accuracy: 0.9890 - val_loss: 0.0923 - val_accuracy: 0.9689\n",
      "Epoch 5/100\n",
      "930/930 - 8s - loss: 0.0291 - accuracy: 0.9916 - val_loss: 0.0924 - val_accuracy: 0.9686\n",
      "Epoch 6/100\n",
      "930/930 - 7s - loss: 0.0243 - accuracy: 0.9930 - val_loss: 0.1003 - val_accuracy: 0.9655\n",
      "Epoch 7/100\n",
      "930/930 - 8s - loss: 0.0227 - accuracy: 0.9932 - val_loss: 0.0911 - val_accuracy: 0.9676\n",
      "Epoch 8/100\n",
      "930/930 - 8s - loss: 0.0185 - accuracy: 0.9942 - val_loss: 0.0861 - val_accuracy: 0.9693\n",
      "Epoch 9/100\n",
      "930/930 - 8s - loss: 0.0175 - accuracy: 0.9948 - val_loss: 0.1081 - val_accuracy: 0.9625\n",
      "Epoch 10/100\n",
      "930/930 - 8s - loss: 0.0145 - accuracy: 0.9957 - val_loss: 0.0965 - val_accuracy: 0.9736\n",
      "Epoch 11/100\n",
      "930/930 - 8s - loss: 0.0143 - accuracy: 0.9959 - val_loss: 0.0979 - val_accuracy: 0.9706\n",
      "Epoch 12/100\n",
      "930/930 - 7s - loss: 0.0129 - accuracy: 0.9961 - val_loss: 0.1239 - val_accuracy: 0.9649\n",
      "Epoch 13/100\n",
      "930/930 - 8s - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.0860 - val_accuracy: 0.9679\n",
      "Epoch 14/100\n",
      "930/930 - 8s - loss: 0.0135 - accuracy: 0.9954 - val_loss: 0.1098 - val_accuracy: 0.9639\n",
      "Epoch 15/100\n",
      "930/930 - 7s - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.1099 - val_accuracy: 0.9713\n",
      "Finished training\n",
      "Saved model\n",
      "Siamese EER: 0.018666666666666668\n",
      "Siamese Accuracy: 0.981\n",
      "SVM Accuracy: 0.9756666666666667\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6213 - acc: 0.9637\n",
      "ANN Accuracy: 0.9636666774749756\n",
      "KNN Accuracy: 0.972\n",
      "Run #6:\n",
      "Loaded data\n",
      "Built model\n",
      "Start training ...\n",
      "Epoch 1/100\n",
      "930/930 - 8s - loss: 0.1812 - accuracy: 0.9383 - val_loss: 0.1567 - val_accuracy: 0.9493\n",
      "Epoch 2/100\n",
      "930/930 - 7s - loss: 0.0735 - accuracy: 0.9777 - val_loss: 0.1210 - val_accuracy: 0.9581\n",
      "Epoch 3/100\n",
      "930/930 - 7s - loss: 0.0505 - accuracy: 0.9848 - val_loss: 0.1027 - val_accuracy: 0.9655\n",
      "Epoch 4/100\n",
      "930/930 - 7s - loss: 0.0377 - accuracy: 0.9889 - val_loss: 0.1140 - val_accuracy: 0.9615\n",
      "Epoch 5/100\n",
      "930/930 - 7s - loss: 0.0284 - accuracy: 0.9915 - val_loss: 0.1230 - val_accuracy: 0.9642\n",
      "Epoch 6/100\n",
      "930/930 - 7s - loss: 0.0235 - accuracy: 0.9930 - val_loss: 0.1220 - val_accuracy: 0.9618\n",
      "Epoch 7/100\n",
      "930/930 - 7s - loss: 0.0231 - accuracy: 0.9926 - val_loss: 0.1259 - val_accuracy: 0.9618\n",
      "Epoch 8/100\n",
      "930/930 - 7s - loss: 0.0214 - accuracy: 0.9935 - val_loss: 0.1394 - val_accuracy: 0.9595\n",
      "Finished training\n",
      "Saved model\n",
      "Siamese EER: 0.038\n",
      "Siamese Accuracy: 0.962\n",
      "SVM Accuracy: 0.9566666666666667\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3212 - acc: 0.9450\n",
      "ANN Accuracy: 0.9449999928474426\n",
      "KNN Accuracy: 0.961\n",
      "Run #7:\n",
      "Loaded data\n",
      "Built model\n",
      "Start training ...\n",
      "Epoch 1/100\n",
      "930/930 - 8s - loss: 0.1723 - accuracy: 0.9418 - val_loss: 0.1568 - val_accuracy: 0.9497\n",
      "Epoch 2/100\n",
      "930/930 - 7s - loss: 0.0748 - accuracy: 0.9769 - val_loss: 0.1444 - val_accuracy: 0.9537\n",
      "Epoch 3/100\n",
      "930/930 - 8s - loss: 0.0496 - accuracy: 0.9852 - val_loss: 0.1578 - val_accuracy: 0.9584\n",
      "Epoch 4/100\n",
      "930/930 - 8s - loss: 0.0359 - accuracy: 0.9887 - val_loss: 0.1456 - val_accuracy: 0.9622\n",
      "Epoch 5/100\n",
      "930/930 - 8s - loss: 0.0292 - accuracy: 0.9913 - val_loss: 0.1396 - val_accuracy: 0.9598\n",
      "Epoch 6/100\n",
      "930/930 - 8s - loss: 0.0244 - accuracy: 0.9929 - val_loss: 0.1406 - val_accuracy: 0.9608\n",
      "Epoch 7/100\n",
      "930/930 - 8s - loss: 0.0222 - accuracy: 0.9930 - val_loss: 0.1428 - val_accuracy: 0.9618\n",
      "Epoch 8/100\n",
      "930/930 - 8s - loss: 0.0176 - accuracy: 0.9947 - val_loss: 0.1465 - val_accuracy: 0.9605\n",
      "Epoch 9/100\n",
      "930/930 - 7s - loss: 0.0154 - accuracy: 0.9954 - val_loss: 0.1372 - val_accuracy: 0.9666\n",
      "Epoch 10/100\n",
      "930/930 - 8s - loss: 0.0165 - accuracy: 0.9948 - val_loss: 0.1728 - val_accuracy: 0.9628\n",
      "Epoch 11/100\n",
      "930/930 - 8s - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.1943 - val_accuracy: 0.9605\n",
      "Epoch 12/100\n",
      "930/930 - 8s - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.1604 - val_accuracy: 0.9618\n",
      "Epoch 13/100\n",
      "930/930 - 8s - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.1581 - val_accuracy: 0.9605\n",
      "Epoch 14/100\n",
      "930/930 - 7s - loss: 0.0109 - accuracy: 0.9967 - val_loss: 0.1613 - val_accuracy: 0.9622\n",
      "Finished training\n",
      "Saved model\n",
      "Siamese EER: 0.034666666666666665\n",
      "Siamese Accuracy: 0.9653333333333334\n",
      "SVM Accuracy: 0.9553333333333334\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4275 - acc: 0.9543\n",
      "ANN Accuracy: 0.9543333053588867\n",
      "KNN Accuracy: 0.956\n",
      "Run #8:\n",
      "Loaded data\n",
      "Built model\n",
      "Start training ...\n",
      "Epoch 1/100\n",
      "930/930 - 9s - loss: 0.1740 - accuracy: 0.9405 - val_loss: 0.1576 - val_accuracy: 0.9520\n",
      "Epoch 2/100\n",
      "930/930 - 8s - loss: 0.0745 - accuracy: 0.9771 - val_loss: 0.1548 - val_accuracy: 0.9568\n",
      "Epoch 3/100\n",
      "930/930 - 8s - loss: 0.0520 - accuracy: 0.9844 - val_loss: 0.1613 - val_accuracy: 0.9503\n",
      "Epoch 4/100\n",
      "930/930 - 8s - loss: 0.0370 - accuracy: 0.9894 - val_loss: 0.1658 - val_accuracy: 0.9611\n",
      "Epoch 5/100\n",
      "930/930 - 8s - loss: 0.0302 - accuracy: 0.9905 - val_loss: 0.1744 - val_accuracy: 0.9561\n",
      "Epoch 6/100\n",
      "930/930 - 8s - loss: 0.0246 - accuracy: 0.9925 - val_loss: 0.1793 - val_accuracy: 0.9530\n",
      "Epoch 7/100\n",
      "930/930 - 8s - loss: 0.0232 - accuracy: 0.9925 - val_loss: 0.1738 - val_accuracy: 0.9598\n",
      "Epoch 8/100\n",
      "930/930 - 8s - loss: 0.0196 - accuracy: 0.9942 - val_loss: 0.1550 - val_accuracy: 0.9588\n",
      "Epoch 9/100\n",
      "930/930 - 8s - loss: 0.0166 - accuracy: 0.9950 - val_loss: 0.1916 - val_accuracy: 0.9541\n",
      "Finished training\n",
      "Saved model\n",
      "Siamese EER: 0.03\n",
      "Siamese Accuracy: 0.9696666666666667\n",
      "SVM Accuracy: 0.9653333333333334\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5267 - acc: 0.9457\n",
      "ANN Accuracy: 0.9456666707992554\n",
      "KNN Accuracy: 0.9613333333333334\n",
      "Run #9:\n",
      "Loaded data\n",
      "Built model\n",
      "Start training ...\n",
      "Epoch 1/100\n",
      "930/930 - 8s - loss: 0.1792 - accuracy: 0.9382 - val_loss: 0.1302 - val_accuracy: 0.9547\n",
      "Epoch 2/100\n",
      "930/930 - 8s - loss: 0.0738 - accuracy: 0.9776 - val_loss: 0.1246 - val_accuracy: 0.9561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "930/930 - 8s - loss: 0.0521 - accuracy: 0.9829 - val_loss: 0.1242 - val_accuracy: 0.9595\n",
      "Epoch 4/100\n",
      "930/930 - 8s - loss: 0.0362 - accuracy: 0.9893 - val_loss: 0.1303 - val_accuracy: 0.9608\n",
      "Epoch 5/100\n",
      "930/930 - 8s - loss: 0.0298 - accuracy: 0.9907 - val_loss: 0.1379 - val_accuracy: 0.9568\n",
      "Epoch 6/100\n",
      "930/930 - 8s - loss: 0.0256 - accuracy: 0.9924 - val_loss: 0.1396 - val_accuracy: 0.9632\n",
      "Epoch 7/100\n",
      "930/930 - 8s - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.1370 - val_accuracy: 0.9645\n",
      "Epoch 8/100\n",
      "930/930 - 7s - loss: 0.0192 - accuracy: 0.9945 - val_loss: 0.1631 - val_accuracy: 0.9541\n",
      "Epoch 9/100\n",
      "930/930 - 8s - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.1354 - val_accuracy: 0.9639\n",
      "Epoch 10/100\n",
      "930/930 - 8s - loss: 0.0143 - accuracy: 0.9959 - val_loss: 0.1701 - val_accuracy: 0.9581\n",
      "Epoch 11/100\n",
      "930/930 - 8s - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.1714 - val_accuracy: 0.9608\n",
      "Epoch 12/100\n",
      "930/930 - 8s - loss: 0.0138 - accuracy: 0.9958 - val_loss: 0.1646 - val_accuracy: 0.9601\n",
      "Finished training\n",
      "Saved model\n",
      "Siamese EER: 0.024\n",
      "Siamese Accuracy: 0.976\n",
      "SVM Accuracy: 0.971\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3458 - acc: 0.9620\n",
      "ANN Accuracy: 0.9620000123977661\n",
      "KNN Accuracy: 0.957\n",
      "[0.968  0.9787 0.9733 0.9767 0.9667 0.981  0.962  0.9653 0.9697 0.976 ]\n",
      "siamese accuracy: 0.9717333333333332 +/- 0.005988507512078635\n",
      "[0.9693 0.9617 0.962  0.9723 0.973  0.9757 0.9567 0.9553 0.9653 0.971 ]\n",
      "svm accuracy: 0.9662333333333333 +/- 0.006739683474268902\n",
      "[0.9613 0.968  0.9617 0.9603 0.9633 0.9637 0.945  0.9543 0.9457 0.962 ]\n",
      "ann accuracy: 0.9585333287715911 +/- 0.007336666560254259\n",
      "[0.9673 0.968  0.9637 0.9753 0.9523 0.972  0.961  0.956  0.9613 0.957 ]\n",
      "knn accuracy: 0.9634 +/- 0.006937498748748645\n"
     ]
    }
   ],
   "source": [
    "data, labels = load_dataset(2, 0.75, acc_only=False)\n",
    "num_cls = 4 # number of classifiers\n",
    "total_accs = np.zeros((runs, num_cls))\n",
    "\n",
    "# Results of this configuration/experiment\n",
    "# EERs = np.array([np.zeros(runs) for _ in range(3*2*2)])\n",
    "\n",
    "for run_n in range(runs):\n",
    "    siamese, ROC, accs = one_run(train_sps, val_sps, test_sps, max_cls, split, data, labels, [], run_n)\n",
    "    for ii, c in enumerate(accs):\n",
    "        total_accs[run_n, ii] = accs[c]\n",
    "    \n",
    "    np.save(os.path.join(results_path, 'osaka', 'classifiers.npy'), total_accs)\n",
    "    \n",
    "#     EERs[4 * model_index + 2*bn + reg , run_n] = EER\n",
    "#     np.save(results_path + 'osaka_filters_eers2.npy', EERs)\n",
    "\n",
    "for ii, c in enumerate(accs):\n",
    "    print(total_accs[:,ii])\n",
    "    print('{} accuracy: {} +/- {}'.format(c, total_accs[:,ii].mean(), total_accs[:,ii].std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "68zo_lIziFii",
    "outputId": "b6a9d60a-7cf9-41bd-b676-6b2cfdc0991e"
   },
   "outputs": [],
   "source": [
    "print('Siamese network direct test accuracy:')\n",
    "siamese.evaluate([l_input_test, r_input_test], b_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iK0wUaUgTFxn"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "print('Siamese network direct test accuracy:')\n",
    "siamese.evaluate([l_input_test, r_input_test], b_labels_test)\n",
    "\n",
    "print('==========SVM==========')\n",
    "classifier = SVC(kernel='poly', degree=10, C=100)\n",
    "feature_exctractor = Model(inputs=[siamese.get_layer('left_input').input,siamese.get_layer('right_input').input], outputs=siamese.get_layer('lambda').output)\n",
    "d_vect = feature_exctractor.predict([l_input, r_input])\n",
    "d_vect_test = feature_exctractor.predict([l_input_test, r_input_test])\n",
    "print(d_vect.shape)\n",
    "\n",
    "classifier.fit(d_vect, b_labels)\n",
    "svc_score = classifier.score(d_vect_test, b_labels_test)\n",
    "print('SVC mean test accuracy:', svc_score*100)\n",
    "\n",
    "pca = PCA(2)\n",
    "colors = ['#800000',\n",
    "          '#bfef45']\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(121)\n",
    "plt.title('Ground Truth')\n",
    "d_vect_test_2d = pca.fit_transform(d_vect_test)\n",
    "plt.scatter(d_vect_test_2d[:, 0], d_vect_test_2d[:, 1], c=[colors[i] for i in b_labels_test], alpha=0.2)\n",
    "plt.subplot(122)\n",
    "plt.title('Prediction')\n",
    "d_vect_test_2d = pca.fit_transform(d_vect_test)\n",
    "plt.scatter(d_vect_test_2d[:, 0], d_vect_test_2d[:, 1], c=[colors[i] for i in classifier.predict(d_vect_test)], alpha=0.2)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# # print('==========OneClassSVM==========')\n",
    "\n",
    "# # outlier_detector = OneClassSVM(kernel='rbf')\n",
    "# # outlier_detector.fit(d_vect, b_labels)\n",
    "# # test_predictions = np.uint8(outlier_detector.predict(d_vect_test) > 0)\n",
    "# # svc_score = (test_predictions == b_labels_test).mean() * 100\n",
    "# # print('OneClassSVM mean test accuracy:', svc_score)\n",
    "\n",
    "# # pca = PCA(2)\n",
    "# # colors = ['#800000',\n",
    "# #           '#bfef45']\n",
    "# # plt.figure(figsize=(16,6))\n",
    "# # plt.subplot(121)\n",
    "# # plt.title('Ground Truth')\n",
    "# # d_vect_test_2d = pca.fit_transform(d_vect_test)\n",
    "# # plt.scatter(d_vect_test_2d[:, 0], d_vect_test_2d[:, 1], c=[colors[i] for i in b_labels_test], alpha=0.2)\n",
    "# # plt.subplot(122)\n",
    "# # plt.title('Prediction')\n",
    "# # d_vect_test_2d = pca.fit_transform(d_vect_test)\n",
    "# # plt.scatter(d_vect_test_2d[:, 0], d_vect_test_2d[:, 1], c=[colors[i] for i in test_predictions], alpha=0.2)\n",
    "# # plt.show()\n",
    "\n",
    "# print('==========ANN==========')\n",
    "\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# classifier = Sequential()\n",
    "# classifier.add(Dense(8, activation='relu', input_shape=(64,)))\n",
    "# classifier.add(Dropout(0.3))\n",
    "# classifier.add(Dense(8, activation='relu'))\n",
    "# classifier.add(Dropout(0.3))\n",
    "# classifier.add(Dense(1, activation='sigmoid'))\n",
    "# classifier.compile(loss='binary_crossentropy', metrics=['acc'], optimizer='adam')\n",
    "# classifier.fit(d_vect, b_labels, verbose=0, epochs=20, batch_size=128)\n",
    "# test_predictions = np.uint8(np.squeeze(classifier.predict(d_vect_test) >= 0.5))\n",
    "# # print(test_predictions[:10])\n",
    "# ann_score = classifier.evaluate(d_vect_test, b_labels_test)[1]\n",
    "# print('ANN mean test accuracy:', ann_score*100)\n",
    "\n",
    "# pca = PCA(2)\n",
    "# colors = ['#800000',\n",
    "#           '#bfef45']\n",
    "# plt.figure(figsize=(16,6))\n",
    "# plt.subplot(121)\n",
    "# plt.title('Ground Truth')\n",
    "# d_vect_test_2d = pca.fit_transform(d_vect_test)\n",
    "# plt.scatter(d_vect_test_2d[:, 0], d_vect_test_2d[:, 1], c=[colors[i] for i in b_labels_test], alpha=0.2)\n",
    "# plt.subplot(122)\n",
    "# plt.title('Prediction')\n",
    "# d_vect_test_2d = pca.fit_transform(d_vect_test)\n",
    "# plt.scatter(d_vect_test_2d[:, 0], d_vect_test_2d[:, 1], c=[colors[i] for i in test_predictions], alpha=0.2)\n",
    "# plt.show()\n",
    "\n",
    "# print('==========KNN==========')\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# knn = KNeighborsClassifier(n_neighbors=5)\n",
    "# knn.fit(d_vect, b_labels)\n",
    "# test_predictions = knn.predict(d_vect_test)\n",
    "# knn_score = knn.score(d_vect_test, b_labels_test)\n",
    "# print('KNN mean test accuracy:', knn_score*100)\n",
    "\n",
    "# pca = PCA(2)\n",
    "# colors = ['#800000',\n",
    "#           '#bfef45']\n",
    "# plt.figure(figsize=(16,6))\n",
    "# plt.subplot(121)\n",
    "# plt.title('Ground Truth')\n",
    "# d_vect_test_2d = pca.fit_transform(d_vect_test)\n",
    "# plt.scatter(d_vect_test_2d[:, 0], d_vect_test_2d[:, 1], c=[colors[i] for i in b_labels_test], alpha=0.2)\n",
    "# plt.subplot(122)\n",
    "# plt.title('Prediction')\n",
    "# d_vect_test_2d = pca.fit_transform(d_vect_test)\n",
    "# plt.scatter(d_vect_test_2d[:, 0], d_vect_test_2d[:, 1], c=[colors[i] for i in test_predictions], alpha=0.2)\n",
    "# plt.show()\n",
    "\n",
    "print('==========GaussionMixture==========')\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gmodel = GaussianMixture(n_components=5)\n",
    "gmodel.fit(d_vect, b_labels)\n",
    "test_predictions =  np.uint8((gmodel.score_samples(d_vect_test) > -55))\n",
    "print(test_predictions)\n",
    "gmodel_score = (test_predictions == b_labels_test).mean()\n",
    "print('Gaussian Mixture mean test accuracy:', gmodel_score*100)\n",
    "\n",
    "pca = PCA(2)\n",
    "colors = ['#800000',\n",
    "          '#bfef45']\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(121)\n",
    "plt.title('Ground Truth')\n",
    "d_vect_test_2d = pca.fit_transform(d_vect_test)\n",
    "plt.scatter(d_vect_test_2d[:, 0], d_vect_test_2d[:, 1], c=[colors[i] for i in b_labels_test], alpha=0.2)\n",
    "plt.subplot(122)\n",
    "plt.title('Prediction')\n",
    "d_vect_test_2d = pca.fit_transform(d_vect_test)\n",
    "plt.scatter(d_vect_test_2d[:, 0], d_vect_test_2d[:, 1], c=[colors[i] for i in test_predictions], alpha=0.2)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "osaka_cls_retrain.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
